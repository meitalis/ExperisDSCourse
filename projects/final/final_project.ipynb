{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,KBinsDiscretizer,MinMaxScaler,StandardScaler,PolynomialFeatures\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve,roc_curve\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest,SelectFromModel,f_classif,chi2\n",
    "\n",
    "from sklearn.decomposition import KernelPCA,PCA\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('train.csv',na_values=[' '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #display(df_train.NOEXCH.unique())\n",
    "# #df_train.head()\n",
    "# #df_test = pd.read_csv('train.csv')\n",
    "\n",
    "# df_train.loc[df_train.NOEXCH == 1, 'NOEXCH']   = 'X'\n",
    "# df_train.loc[df_train.NOEXCH == 0, 'NOEXCH']   = np.nan\n",
    "# df_train.loc[df_train.NOEXCH == '1', 'NOEXCH']   = 'X'\n",
    "# df_train.loc[df_train.NOEXCH == '0', 'NOEXCH']   = np.nan\n",
    "\n",
    "# df_train.NOEXCH.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(df_train.isna().sum())\n",
    "#df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features1= [] \n",
    "# #list(['cat1','cat2','cat3'])\n",
    "\n",
    "# for i in range(3,25):\n",
    "#     features1.append('RAMNT_' + str(i) )\n",
    "# features1.append()\n",
    "# df_train[features1].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train[['RAMNTALL']].isna().sum())\n",
    "# df_train[['RAMNTALL']].apply(lambda x: x.corr(df_train.TARGET_D))\n",
    "\n",
    "# #df_train.drop(\"TARGET_B\", axis=1).apply(lambda x: x.corr(df_train.TARGET_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c = df_train.corr().abs()\n",
    "\n",
    "# s = c.unstack()\n",
    "\n",
    "# so = s.sort_values(kind=\"quicksort\")\n",
    "\n",
    "# display(so.shape)\n",
    "\n",
    "# print(so[-2000:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.corr()['TARGET_B']\n",
    "# cols=df_train.columns[(df_train.isna().sum() == 0)]\n",
    "# cols = cols[cols != 'OSOURCE']\n",
    "# cols = cols[cols != 'STATE']\n",
    "# display(cols)\n",
    "\n",
    "# df_new[cols].apply(lambda x: x.corr(df_new.TARGET_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "# df_train[['AGE']] = imputer.fit_transform(df_train[['AGE']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_train.drop(['TARGET_B','TARGET_D'],axis=1)\n",
    "# y = df_train.TARGET_B\n",
    "\n",
    "# X_train,X_test,y_train ,y_test = train_test_split(X,y,random_state = 42,train_size = 0.8,test_size=0.2)\n",
    "# #X_train,X_test ,y_train ,y_test\n",
    "\n",
    "# #print(X_train.isna().sum().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sub = X_train[['AGE']]\n",
    "# X_test_sub = X_test[['AGE']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(X_train_sub,y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(model,X_test_sub,y_test,cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(model.score(X_test_sub, y_test)))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd_clf = SGDClassifier(random_state=0,max_iter=50)\n",
    "# sgd_clf.fit(X_train_sub,y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(sgd_clf,X_test_sub,y_test,cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(sgd_clf.score(X_test_sub, y_test)))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_clf = RandomForestClassifier(n_estimators=1)\n",
    "# forest_clf.fit(X_train_sub,y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(forest_clf,X_test_sub,y_test,cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(forest_clf.score(X_test_sub, y_test)))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression + PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly = PolynomialFeatures(degree=4)\n",
    "\n",
    "# model = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "# model = make_pipeline(poly, model)\n",
    "# model.fit(X_train_sub, y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(model,X_test_sub,y_test,cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(model.score(X_test_sub, y_test)))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier + PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly = PolynomialFeatures(degree=4)\n",
    "\n",
    "# sgd_clf = SGDClassifier(random_state=0,max_iter=50)\n",
    "# sgd_clf = make_pipeline(poly, sgd_clf)\n",
    "# sgd_clf.fit(X_train_sub, y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(sgd_clf,X_test_sub,y_test,cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(sgd_clf.score(X_test_sub, y_test)))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly = PolynomialFeatures(degree=4)\n",
    "\n",
    "# knn = make_pipeline(poly, KNeighborsClassifier(n_neighbors=5))\n",
    "# knn.fit(X_train_sub, y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(knn,X_test_sub,y_test,cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(knn.score(X_test_sub, y_test)))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(X_train.isna().sum())\n",
    "# # X_train.info()\n",
    "# # print(X_train.select_dtypes(include=['float64','int64']).columns)\n",
    "# X = df_train.drop(['TARGET_B','TARGET_D'],axis=1)\n",
    "# y = df_train.TARGET_B\n",
    "\n",
    "# print(X.shape)\n",
    "\n",
    "# numeric_features = X.select_dtypes(include=['float64','int64']).columns\n",
    "# numeric_transformer = Pipeline([('imputer',SimpleImputer(strategy='median'))])\n",
    "\n",
    "# #create the preprocessing pipeline for the categorial data\n",
    "# category_features = X.select_dtypes(include=['object']).columns\n",
    "# category_transformer = Pipeline([('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "#                                ('onehot',OneHotEncoder())])\n",
    "\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#      ('num',numeric_transformer,numeric_features)\n",
    "#      #('cat',category_transformer,category_features)\n",
    "# ])#,remainder='passthrough')\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('pre',preprocessor)\n",
    "#     #('cls',RandomForestClassifier(n_estimators=5))\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "# #X_train,X_test,y_train ,y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n",
    "# #X_train,X_test ,y_train ,y_test\n",
    "\n",
    "# X_train_pre = clf.fit_transform(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VarianceThreshold\n",
    "\n",
    "\n",
    "# print(X_train_pre.shape)\n",
    "\n",
    "# sel = VarianceThreshold(threshold=0.05)\n",
    "# X_train_pre = sel.fit_transform(X_train_pre)\n",
    "\n",
    "# print(X_train_pre.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #X_train_pre_centered = X_train_pre - X_train_pre.mean(axis=0)\n",
    "# df = pd.DataFrame(X_train_pre)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train ,y_test = train_test_split(df,y,test_size=0.2,random_state = 42,stratify=y)\n",
    "# X_train,X_test ,y_train ,y_test\n",
    "\n",
    "# print(X_train_pre.shape)\n",
    "# # print(X_train_pre.info())\n",
    "# # X_train = df.select_dtypes(include=['float64','int64'])\n",
    "# #print(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA & RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components = 20)\n",
    "# X_train_after_pca = pca.fit_transform(X_train)\n",
    "# X_test_after_pca = pca.transform(X_test)\n",
    "\n",
    "# forest_clf = RandomForestClassifier(n_estimators=15)\n",
    "# forest_clf.fit(X_train_after_pca, y_train)\n",
    "\n",
    "# #y_pred = model.predict(X_test_sub)\n",
    "# y_test_pred = cross_val_predict(forest_clf,X_test_after_pca, y_test, cv=3)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "# accuracy = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy  classifier on test set: {:.2f}'.format(accuracy))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_selected = make_pipeline(\n",
    "#         SelectKBest(f_classif, k=15),  LinearSVC()\n",
    "# )\n",
    "# clf_selected.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_test_pred = cross_val_predict(clf_selected,X_test, y_test, cv=3,)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "# accuracy = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of classifier on test set: {:.2f}'.format(accuracy))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# numeric_features = ['AGE']\n",
    "# numeric_transformer = Pipeline([('imputer',SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "# category_features = ['STATE','GENDER']\n",
    "# category_transformer = Pipeline([('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "#                                ('onehot',OneHotEncoder(sparse=False))])\n",
    "\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#      ('num',numeric_transformer,numeric_features),\n",
    "#      ('cat',category_transformer,category_features)\n",
    "# ])#,remainder='passthrough')\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('pre',preprocessor)\n",
    "#     #('cls',RandomForestClassifier(n_estimators=5))\n",
    "# ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_train = pd.read_csv('train.csv',na_values=[' '])\n",
    "# #print(df_train.dtypes)\n",
    "\n",
    "# df_train.loc[df_train.NOEXCH == 1, 'NOEXCH']   = 'X'\n",
    "# df_train.loc[df_train.NOEXCH == 0, 'NOEXCH']   = np.nan\n",
    "# df_train.loc[df_train.NOEXCH == '1', 'NOEXCH']   = 'X'\n",
    "# df_train.loc[df_train.NOEXCH == '0', 'NOEXCH']   = np.nan\n",
    "\n",
    "# df_train.drop(['OSOURCE'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# X = df_train.drop(['TARGET_B','TARGET_D'],axis=1)\n",
    "# y = df_train.TARGET_B\n",
    "\n",
    "# X_train_pre = clf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train ,y_test = train_test_split(X_train_pre,y,test_size=0.2,random_state = 42,stratify=y)\n",
    "# X_train.shape\n",
    "# #X_train,X_test ,y_train ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_selected = make_pipeline(\n",
    "#         SelectKBest(f_classif, k=15),  LinearSVC()\n",
    "# )\n",
    "# clf_selected.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_test_pred = cross_val_predict(clf_selected,X_test, y_test, cv=3,)\n",
    "# conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "# f1 = f1_score(y_test,y_test_pred)\n",
    "# accuracy = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "# print('Accuracy of classifier on test set: {:.2f}'.format(accuracy))\n",
    "# print('f1 of logistic regression classifier on test set: {:.2f}'.format(f1))\n",
    "# display(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########     2    ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (6,8,9,10,11,12,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv',na_values=[' '])\n",
    "df_train_true = df_train[df_train.TARGET_B==1]\n",
    "df_train_false = df_train[df_train.TARGET_B==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95412, 481)\n",
      "(4843, 481)\n",
      "(90569, 481)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_train_true.shape)\n",
    "print(df_train_false.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(43587, 481)\n",
      "(138999, 481)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# df_train_false = shuffle(df_train_false)\n",
    "\n",
    "n = df_train_false.shape[0] * 0.5\n",
    "n = n / df_train_true.shape[0]\n",
    "n = int(np.round(n,0))\n",
    "print(n)\n",
    "\n",
    "\n",
    "df_train_2 = pd.concat([df_train_true] * n )\n",
    "print(df_train_2.shape)\n",
    "df_train_2 = pd.concat([df_train, df_train_2])\n",
    "print(df_train_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = df_train_true.corr()\n",
    "\n",
    "# c1 = corr.abs().unstack()\n",
    "# s = c1.sort_values(ascending = False)\n",
    "# t = s[s == 1]\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_target = df_train.corr()['TARGET_B']\n",
    "\n",
    "# corr_target[corr_target > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (6,8,9,10,11,12,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier on test set: 0.65\n",
      "f1 classifier on test set: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[17743,   371],\n",
       "       [ 9344,   342]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv',na_values=[' '])\n",
    "df_new = df_train_2[['RAMNT_5','MC1','MC2','MC3','TPE10','TPE1','TPE2','TPE3','TPE4','TPE7','TPE9','TPE12','PEC2',\n",
    "                  'CARDGIFT','NGIFTALL','RAMNTALL','INCOME','AGE']]\n",
    "#                    'HHAS4',\n",
    "#                   'HHAS3','HHAS2','HHAS1','IC22','IC21','IC20','IC19','OCC12','LFC1',\n",
    "#                   'IC18' ,'TPE1', 'TPE13','IC16', 'OCC3' ,'EIC6','EIC3','EIC2','EIC1', 'OCC11','OCC10','OCC8',\n",
    "#                    'OCC6','OCC2','OCC1','LFC10','LFC9','LFC8','LFC7','LFC6','IC17','IC15', 'LFC4', 'LFC3', 'LFC2']]\n",
    "\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='mean')),\n",
    "    ('scaler',StandardScaler())\n",
    "    #('cls',RandomForestClassifier(n_estimators=5))\n",
    "])\n",
    "\n",
    "\n",
    "X = df_new\n",
    "y = df_train_2.TARGET_B\n",
    "\n",
    "X_pre = clf.fit_transform(X)\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X_pre,y,test_size=0.2,random_state = 42,stratify=y)\n",
    "\n",
    "     \n",
    "clf_selected = make_pipeline(\n",
    "        SelectKBest(f_classif, k=15),  LinearSVC()\n",
    ")\n",
    "clf_selected.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_test_pred = cross_val_predict(clf_selected,X_test, y_test, cv=3,)\n",
    "conf_mat = confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "f1 = f1_score(y_test,y_test_pred)\n",
    "accuracy = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.2f}'.format(accuracy))\n",
    "print('f1 classifier on test set: {:.2f}'.format(f1))\n",
    "display(conf_mat)\n",
    "\n",
    "           \n",
    "  \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
