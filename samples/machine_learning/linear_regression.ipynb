{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = [6,8,10,14,18]\n",
    "toppings = [2,1,0,2,0]\n",
    "price = [7,9,13,17.5,18]\n",
    "\n",
    "X_train = pd.DataFrame({'Diameter':diameter,\n",
    "                   'Toppings':toppings})\n",
    "\n",
    "y_train = pd.DataFrame({'Price':price})\n",
    "X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "model.coef_,model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b = np.column_stack((np.ones(5),X_train))\n",
    "x_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_best = np.linalg.inv(x_b.T @ x_b) @ x_b.T @y_train\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x_model = np.arange(20)\n",
    "y_model = np.arange(20)\n",
    "z_model = theta_best.iloc[0,0] + x_model * theta_best.iloc[1,0] + y_model * theta_best.iloc[2,0] \n",
    "x_model,y_model,z_model\n",
    "\n",
    "ax.plot(x_model,y_model,z_model)\n",
    "ax.scatter3D(X_train.Diameter,X_train.Toppings,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "m = 10000\n",
    "rng = np.random.RandomState(0)\n",
    "X = 2 * rng.rand(m,1)\n",
    "\n",
    "y = 4 + 3 * X + rng.randn(m,1)\n",
    "\n",
    "x_b = np.column_stack((np.ones(m),X))\n",
    "\n",
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "\n",
    "theta = rng.randn(2,1)\n",
    "#print(\"org theta\",theta)\n",
    "tolerance_theta = 0.00002\n",
    "tolerance_gra = 0.00005\n",
    "count = 0\n",
    "\n",
    "for iter in range(n_iterations):\n",
    "    count += 1\n",
    "    gra = 2 /m * x_b.T @ (x_b @ theta -y)\n",
    "    \n",
    "    prev_theta = theta\n",
    "    theta = theta - eta * gra\n",
    "\n",
    "    sqrt_comp_grad = np.sqrt((gra**2).sum())\n",
    "    #print(\"sqrt_comp_grad\",sqrt_comp_grad)\n",
    "\n",
    "    sqrt_comp = np.sqrt(((prev_theta - theta)**2).sum())\n",
    "    #print('sqrt_comp',sqrt_comp)\n",
    "    if sqrt_comp_grad < tolerance_gra:\n",
    "        print(\"count\", count,\"sqrt_comp_grad\",sqrt_comp_grad)\n",
    "        break\n",
    "\n",
    "    #if sqrt_comp < tolerance_theta:\n",
    "    #    print(\"count\", count)\n",
    "    #    break\n",
    "\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "m = 100000\n",
    "rng = np.random.RandomState(0)\n",
    "X = 2 * rng.rand(m,1)\n",
    "y = 4 + 3 * X + rng.randn(m,1)\n",
    "\n",
    "x_b = np.column_stack((np.ones(m),X))\n",
    "\n",
    "theta = rng.randn(2,1)\n",
    "\n",
    "count = 0\n",
    "\n",
    "n_epochs = 50\n",
    "t0,t1 = 5,50\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0/ (t +t1)\n",
    "\n",
    "theta = rng.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = rng.randint(m)\n",
    "        x_i = x_b[random_index:random_index +1]\n",
    "        y_i = y[random_index:random_index +1]\n",
    "        gradients = 2 * x_i.T @ (x_i @ theta - y_i)\n",
    "        eta  = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100000\n",
    "rng = np.random.RandomState(0)\n",
    "X = 2 * rng.rand(m,1)\n",
    "y = 4 + 3 * X + rng.randn(m,1)\n",
    "\n",
    "x_b = np.column_stack((np.ones(m),X))\n",
    "\n",
    "theta = rng.randn(2,1)\n",
    "\n",
    "count = 0\n",
    "\n",
    "n_epochs = 50\n",
    "t0,t1 = 5,50\n",
    "batch_size = 10\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0/ (t +t1)\n",
    "\n",
    "theta = rng.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_indexes = rng.randint(m,size=batch_size)\n",
    "        np.random.shuffle(x_b)\n",
    "        x_idxes = x_b[random_indexes]\n",
    "        #print('x_idxes',x_idxes.shape)\n",
    "        y_idxes = y[random_indexes]\n",
    "        #print('y_idxes',y_idxes.shape)\n",
    "        gradients = 2 * x_idxes.T @ (x_idxes @ theta - y_idxes)\n",
    "        eta  = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20\n",
    "rng = np.random.RandomState(0)\n",
    "idx = rng.randint(m,size=5)\n",
    "idx\n",
    "\n",
    "X = 2 * rng.rand(m,1)\n",
    "x_b = np.column_stack((np.ones(m),X))\n",
    "\n",
    "np.random.shuffle(x_b)\n",
    "\n",
    "#display(idx, X)\n",
    "display(idx, x_b[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polynomianl regression\n",
    "### find the best polynomianl fir ti the function f(x) = sin(x) in the range o,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=True,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression(copy_X=True,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         n_jobs=None,\n",
       "                                                         normalize=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'linearregression__fit_intercept': [True, False],\n",
       "                         'linearregression__normalize': [True, False],\n",
       "                         'polynomialfeatures__degree': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#x = np.linspace(0,10,100).reshape(-1,1)\n",
    "x =  10 * np.random.rand(50,1)\n",
    "y = np.sin(x)\n",
    "\n",
    "def PolynominalRegression(degree = 2,**kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                        LinearRegression(**kwargs))\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree':np.arange(30),\n",
    "             'linearregression__fit_intercept':[True,False],\n",
    "             'linearregression__normalize':[True,False]}\n",
    "\n",
    "grid = GridSearchCV(PolynominalRegression(),param_grid,cv=7)\n",
    "grid.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linearregression__fit_intercept': True,\n",
       " 'linearregression__normalize': True,\n",
       " 'polynomialfeatures__degree': 20}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "m = 10000\n",
    "rng = np.random.RandomState(0)\n",
    "X = 2 * rng.rand(m,1)\n",
    "y = 4 + 3 * X + rng.randn(m,1)\n",
    "\n",
    "X_train,X_test,y_train ,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
    "X_train.shape,X_test.shape,y_train ,y_test\n",
    "\n",
    "x_t = np.column_stack((np.ones(8000),X_train))\n",
    "x_test = np.column_stack((np.ones(2000),X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_lin_reg_rmse -1\n",
      "min_lin_reg_rmse 4.890404553000327\n",
      "min_lin_reg_rmse 3.307766661542431\n",
      "min_lin_reg_rmse 2.3224788969435344\n",
      "min_lin_reg_rmse 1.7372015541620442\n",
      "min_lin_reg_rmse 1.4129373460740526\n",
      "min_lin_reg_rmse 1.2465181151125193\n",
      "min_lin_reg_rmse 1.165712989443563\n",
      "min_lin_reg_rmse 1.1270059924720177\n",
      "min_lin_reg_rmse 1.1077477607673512\n",
      "min_lin_reg_rmse 1.0972273494448965\n",
      "min_lin_reg_rmse 1.0906277062646113\n",
      "min_lin_reg_rmse 1.0858300664949059\n",
      "min_lin_reg_rmse 1.081908694452219\n",
      "min_lin_reg_rmse 1.0784576659392118\n",
      "min_lin_reg_rmse 1.075296452462214\n",
      "min_lin_reg_rmse 1.0723423220407187\n",
      "min_lin_reg_rmse 1.069555185766072\n",
      "min_lin_reg_rmse 1.0669137387358174\n",
      "min_lin_reg_rmse 1.064405102947065\n",
      "min_lin_reg_rmse 1.0620203027628101\n",
      "min_lin_reg_rmse 1.0597522680930451\n",
      "min_lin_reg_rmse 1.0575949390818693\n",
      "min_lin_reg_rmse 1.055542854900212\n",
      "min_lin_reg_rmse 1.0535909580023533\n",
      "min_lin_reg_rmse 1.0517344960360673\n",
      "min_lin_reg_rmse 1.0499689691402874\n",
      "min_lin_reg_rmse 1.0482900990549304\n",
      "min_lin_reg_rmse 1.0466938091628428\n",
      "min_lin_reg_rmse 1.0451762102895685\n",
      "min_lin_reg_rmse 1.0437335897071314\n",
      "min_lin_reg_rmse 1.0423624020266595\n",
      "min_lin_reg_rmse 1.0410592612715857\n",
      "min_lin_reg_rmse 1.0398209337331967\n",
      "min_lin_reg_rmse 1.0386443313758873\n",
      "min_lin_reg_rmse 1.0375265056518228\n",
      "min_lin_reg_rmse 1.0364646416381973\n",
      "min_lin_reg_rmse 1.035456052442242\n",
      "min_lin_reg_rmse 1.03449817383865\n",
      "min_lin_reg_rmse 1.0335885591161864\n",
      "min_lin_reg_rmse 1.0327248741178099\n",
      "min_lin_reg_rmse 1.0319048924633496\n",
      "min_lin_reg_rmse 1.03112649094672\n",
      "min_lin_reg_rmse 1.030387645101457\n",
      "min_lin_reg_rmse 1.0296864249294453\n",
      "min_lin_reg_rmse 1.0290209907883416\n",
      "min_lin_reg_rmse 1.0283895894335473\n",
      "min_lin_reg_rmse 1.0277905502107636\n",
      "min_lin_reg_rmse 1.0272222813952399\n",
      "min_lin_reg_rmse 1.0266832666738384\n",
      "min_lin_reg_rmse 1.0261720617660368\n",
      "min_lin_reg_rmse 1.025687291179965\n",
      "min_lin_reg_rmse 1.0252276450995446\n",
      "min_lin_reg_rmse 1.0247918763987987\n",
      "min_lin_reg_rmse 1.0243787977793817\n",
      "min_lin_reg_rmse 1.0239872790273867\n",
      "min_lin_reg_rmse 1.023616244385513\n",
      "min_lin_reg_rmse 1.023264670036688\n",
      "min_lin_reg_rmse 1.0229315816953002\n",
      "min_lin_reg_rmse 1.022616052302224\n",
      "min_lin_reg_rmse 1.022317199819894\n",
      "min_lin_reg_rmse 1.0220341851237402\n",
      "min_lin_reg_rmse 1.0217662099863702\n",
      "min_lin_reg_rmse 1.0215125151509674\n",
      "min_lin_reg_rmse 1.0212723784904436\n",
      "min_lin_reg_rmse 1.0210451132489848\n",
      "min_lin_reg_rmse 1.020830066362707\n",
      "min_lin_reg_rmse 1.0206266168562337\n",
      "min_lin_reg_rmse 1.0204341743121021\n",
      "min_lin_reg_rmse 1.0202521774099942\n",
      "min_lin_reg_rmse 1.0200800925328837\n",
      "min_lin_reg_rmse 1.0199174124372918\n",
      "min_lin_reg_rmse 1.0197636549849265\n",
      "min_lin_reg_rmse 1.0196183619330836\n",
      "min_lin_reg_rmse 1.0194810977812763\n",
      "min_lin_reg_rmse 1.0193514486716504\n",
      "min_lin_reg_rmse 1.0192290213408364\n",
      "min_lin_reg_rmse 1.0191134421209695\n",
      "min_lin_reg_rmse 1.0190043559877062\n",
      "min_lin_reg_rmse 1.018901425653141\n",
      "min_lin_reg_rmse 1.0188043307016112\n",
      "min_lin_reg_rmse 1.0187127667664648\n",
      "min_lin_reg_rmse 1.0186264447459308\n",
      "min_lin_reg_rmse 1.0185450900563229\n",
      "min_lin_reg_rmse 1.0184684419208678\n",
      "min_lin_reg_rmse 1.018396252692526\n",
      "min_lin_reg_rmse 1.0183282872092458\n",
      "min_lin_reg_rmse 1.0182643221801453\n",
      "min_lin_reg_rmse 1.018204145601198\n",
      "min_lin_reg_rmse 1.0181475561990443\n",
      "min_lin_reg_rmse 1.0180943629016193\n",
      "min_lin_reg_rmse 1.0180443843343445\n",
      "min_lin_reg_rmse 1.0179974483406824\n",
      "min_lin_reg_rmse 1.017953391525909\n",
      "min_lin_reg_rmse 1.0179120588230088\n",
      "min_lin_reg_rmse 1.0178733030796514\n",
      "min_lin_reg_rmse 1.017836984665242\n",
      "min_lin_reg_rmse 1.0178029710971046\n",
      "min_lin_reg_rmse 1.0177711366848776\n",
      "min_lin_reg_rmse 1.017741362192261\n",
      "min_lin_reg_rmse 1.0177135345152817\n",
      "min_lin_reg_rmse 1.0176875463762918\n",
      "min_lin_reg_rmse 1.0176632960329404\n",
      "min_lin_reg_rmse 1.0176406870014065\n",
      "min_lin_reg_rmse 1.0176196277932013\n",
      "min_lin_reg_rmse 1.0176000316648925\n",
      "min_lin_reg_rmse 1.017581816380123\n",
      "min_lin_reg_rmse 1.0175649039833345\n",
      "min_lin_reg_rmse 1.0175492205846275\n",
      "min_lin_reg_rmse 1.017534696155219\n",
      "min_lin_reg_rmse 1.0175212643329865\n",
      "min_lin_reg_rmse 1.0175088622376076\n",
      "min_lin_reg_rmse 1.0174974302948294\n",
      "min_lin_reg_rmse 1.017486912069423\n",
      "min_lin_reg_rmse 1.0174772541064039\n",
      "min_lin_reg_rmse 1.0174684057801093\n",
      "min_lin_reg_rmse 1.0174603191507592\n",
      "min_lin_reg_rmse 1.0174529488281239\n",
      "min_lin_reg_rmse 1.017446251841962\n",
      "min_lin_reg_rmse 1.0174401875188899\n",
      "min_lin_reg_rmse 1.0174347173653746\n",
      "min_lin_reg_rmse 1.0174298049565431\n",
      "min_lin_reg_rmse 1.01742541583053\n",
      "min_lin_reg_rmse 1.0174215173880885\n",
      "min_lin_reg_rmse 1.0174180787972051\n",
      "min_lin_reg_rmse 1.0174150709024754\n",
      "min_lin_reg_rmse 1.017412466139006\n",
      "min_lin_reg_rmse 1.0174102384506198\n",
      "min_lin_reg_rmse 1.0174083632121502\n",
      "min_lin_reg_rmse 1.0174068171556288\n",
      "min_lin_reg_rmse 1.0174055783001696\n",
      "min_lin_reg_rmse 1.0174046258853693\n",
      "min_lin_reg_rmse 1.0174039403080506\n",
      "min_lin_reg_rmse 1.0174035030621817\n",
      "min_lin_reg_rmse 1.0174032966818196\n",
      "min_lin_reg_rmse 1.0174032966818196\n",
      "min_lin_reg_rmse 1.0174032966818196\n",
      "min_lin_reg_rmse 1.0174032966818196\n",
      "min_lin_reg_rmse 1.0174032966818196\n",
      "break 1.03112649094672 count 139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.98231132],\n",
       "       [3.02000814]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "\n",
    "theta = rng.randn(2,1)\n",
    "\n",
    "#tolerance = 0.001\n",
    "n_iter_no_change = 5\n",
    "#n_iter_no_change_counter = 0\n",
    "#prev_lin_reg_rmse = 0\n",
    "count = 0\n",
    "min_lin_reg_rmse = -1\n",
    "\n",
    "for iter in range(n_iterations):\n",
    "    count += 1\n",
    "    gra = 2 /m * x_t.T @ (x_t @ theta -y_train)\n",
    "    \n",
    "    prev_theta = theta\n",
    "    theta = theta - eta * gra\n",
    "    \n",
    "    predictions = x_test @ theta\n",
    "    \n",
    "    cur_lin_reg_rmse = np.sqrt(mse(y_test,predictions))\n",
    "    \n",
    "    print(\"min_lin_reg_rmse\" , min_lin_reg_rmse)\n",
    "    if (min_lin_reg_rmse == -1) | (cur_lin_reg_rmse <= min_lin_reg_rmse):\n",
    "        min_lin_reg_rmse = cur_lin_reg_rmse\n",
    "        n_iter_no_change_counter = 0\n",
    "    else:\n",
    "        n_iter_no_change_counter += 1\n",
    "        \n",
    "        \n",
    "    if n_iter_no_change_counter == n_iter_no_change:\n",
    "        print(\"break\" , lin_reg_rmse,'count',count)\n",
    "        break\n",
    "    \n",
    "    prev_lin_reg_rmse = lin_reg_rmse\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Basis - not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class GuassianFeatures(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,N,width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "    \n",
    "    @staticmethod\n",
    "    def _gauss_basis(x,y,width,axis = None):\n",
    "        arg = (x-y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg ** 2,axis))\n",
    "    \n",
    "    def fit(self,X,y = None):\n",
    "        self.centers_ = np.linspace(X.min(),X.max(),self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return self._gauss_basis(X[:,:,np.newaxis],self.centers_,self.width_,axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "gauss_model = make_pipeline(GuassianFeatures(20),\n",
    "                           LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
