{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import  StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_path = 'mnist-original.mat'\n",
    "\n",
    "mnist = loadmat(mnist_path)\n",
    "X = mnist['data'].T\n",
    "y = mnist['label'][0]\n",
    "#display(X.shape , y.shape)\n",
    "\n",
    "# Scale all X values\n",
    "scaler = StandardScaler()\n",
    "X_scaled  = scaler.fit_transform(X)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.0005,train_size=0.0005, random_state=0)\n",
    "train_index, test_index = next(sss.split(X=X_scaled, y=y))   \n",
    "\n",
    "X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "#display(y_train[:5])\n",
    "df_y_train = pd.get_dummies(y_train)\n",
    "y_train = df_y_train.values\n",
    "#display(y_train[:5])\n",
    "\n",
    "df_y_test = pd.get_dummies(y_test)\n",
    "y_test = df_y_test.values\n",
    "\n",
    "\n",
    "display('X_train shape ', X_train.shape,'X_test shape' , X_test.shape)\n",
    "display('Y_train shape ', y_train.shape,'Y_test shape' , y_test.shape)\n",
    "display(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPerceptron(BaseEstimator):\n",
    "    \n",
    "    #layers - includes input, #hidden, output\n",
    "    def __init__(self,layers_len,eta=0,random_state=50):\n",
    "        self.random_state = random_state\n",
    "        self.eta = eta\n",
    "        self.n_layers = len(layers_len)\n",
    "        self.layers_len = layers_len\n",
    "       \n",
    "        self.init_weights()\n",
    "     \n",
    "    \n",
    "    def init_weights(self):\n",
    "        rng = np.random.RandomState(self.random_state)       \n",
    "                \n",
    "        layers_len_next = self.layers_len.copy()\n",
    "        self.weights = []\n",
    "        layers_len_next.pop(0)\n",
    "        \n",
    "        #print(self.layers_len)\n",
    "        \n",
    "#         for layer_len, layer_len_next in zip(self.layers_len, layers_len_next):\n",
    "#             #print(layer_len,layer_len_next)\n",
    "                        \n",
    "#             w = rng.normal(loc=0.0,scale=0.1,size=[layer_len_next,layer_len + 1])\n",
    "#             #print('w',w)\n",
    "            \n",
    "#             self.weights.append(w)\n",
    "        \n",
    "        '''\n",
    "        for debug the sample page 376\n",
    "        '''\n",
    "        self.weights.append(np.array([[0.5, 0, 0.3],\n",
    "                                   [-0.2, 0.4, 0.7],\n",
    "                                   [0,-0.5, -0.1]]))\n",
    "        self.weights.append(np.array([[-0.5, 0.4, 0,0],\n",
    "                                   [0.3, 0.6, 0.4,0]]))\n",
    "        self.weights.append(np.array([[0.5, 0.7, 0]]))\n",
    "                            \n",
    "        \n",
    "        #print('weights', self.weights)\n",
    "        return self.weights\n",
    "    \n",
    "    def train(self,X,y,n_iter=50):\n",
    "    \n",
    "        n_samples = y.shape[0]\n",
    "        #print('n_iter',n_iter)\n",
    "        \n",
    "        for it in range(n_iter):\n",
    "            #print('train it',it)\n",
    "            for idx, sample in enumerate(X):\n",
    "                self.back_propagation(sample.values, y[idx].values)\n",
    "           \n",
    "            \n",
    "    def back_propagation(self, X,y):\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        print('x shape',n_samples)\n",
    "    \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        #print('[back_propagation] layers_net \\n',layers_net,end='\\n\\n')\n",
    "        #print('[back_propagation] layers_input \\n',layers_input,end='\\n\\n')\n",
    "            \n",
    "        errors = [None] * self.n_layers\n",
    "        sigmas = [None] * self.n_layers\n",
    "        \n",
    "#         print('[back_propagation] errors[-1] before ',layers_input[-1].shape)\n",
    "#         print('[back_propagation] errors[-1] before ',y.shape)\n",
    "        errors[-1] = (layers_input[-1] - y) * self.error_part(layers_input[-1])\n",
    "        #print('[back_propagation] errors[-1]  after',errors)\n",
    "            \n",
    "        for layer_index in np.arange(self.n_layers - 2  ,0 , -1):\n",
    "            #print('[back_propagation] LAYER ',layer_index)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_weights = np.delete(layer_weights, -1, axis=1) #remove weight for bias\n",
    "            #print('[back_propagation] layer_weights after remove bias \\n',layer_weights,end='\\n\\n')  \n",
    "            \n",
    "            sigmas[layer_index] = self.sigma(errors[layer_index+1],layer_weights)\n",
    "            #print('[back_propagation] sigmas \\n', sigmas[layer_index],end='\\n\\n') \n",
    "                       \n",
    "            layer_input = layers_input[layer_index]\n",
    "            layer_input = np.delete(layer_input, -1, axis=1)\n",
    "            #print('[back_propagation] layer_input after remove bias',layer_input,end='\\n\\n')\n",
    "            \n",
    "            errors[layer_index] =  sigmas[layer_index] * self.error_part(layer_input)\n",
    "            #print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "        \n",
    "        print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "            \n",
    "            \n",
    "        #update weights\n",
    "        #print('[back_propagation] UPDATE WEIGHTS' ,end='\\n\\n') \n",
    "        tmp_weights = [None] * self.n_layers\n",
    "        for layer_index in np.arange(self.n_layers - 1):\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_input = layers_input[layer_index]\n",
    "                                         \n",
    "            print('[back_propagation] layer_weights',layer_weights ,end='\\n\\n') \n",
    "            print('[back_propagation] layer_input',layer_input ,end='\\n\\n') \n",
    "            print(errors[layer_index+1].transpose())\n",
    "           \n",
    "            print('errors transpose', errors[layer_index+1].transpose().shape,'layer_input reshape [sample,]',\n",
    "                  layer_input.reshape(-1,1).shape ,end='\\n\\n') \n",
    "#       self.layers_len[layer_index]+1,n_samples\n",
    "            \n",
    "            tmp_weights =  np.dot(errors[layer_index+1].transpose(), layer_input.reshape(-1,1).transpose())\n",
    "            print('[back_propagation] tmp_weights',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            tmp_weights =  tmp_weights * self.eta\n",
    "            print('[back_propagation] tmp_weights * eta',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            self.weights[layer_index]  = self.weights[layer_index] - tmp_weights\n",
    "            print('[back_propagation]  comp weights',self.weights[layer_index] ,end='\\n\\n') \n",
    "        \n",
    "        \n",
    "        print('[back_propagation]  self.weights',self.weights ,end='\\n\\n') \n",
    "       \n",
    "      \n",
    "        \n",
    "    def foward_propagation(self, X):\n",
    "        \n",
    "        #print('[foward_propagation] n_layers',self.n_layers)\n",
    "        \n",
    "        layers_input = [None] * self.n_layers\n",
    "        layers_net = [None] * self.n_layers\n",
    "        \n",
    "        \n",
    "        layer_input = X\n",
    "        #print('[foward_propagation] layer_input \\n',layer_input)\n",
    "        \n",
    "        layers_net[0] = np.array(layer_input.ravel())\n",
    "        for layer_index in range(self.n_layers - 1):\n",
    "            #print('foward_propagation layer_index',layer_index)\n",
    "            n_examples = layer_input.shape[0]\n",
    "            #print('n_examples',n_examples,'layer_input',layer_input.shape)\n",
    "            layer_input = np.c_[ layer_input, np.ones((n_examples,1))]  \n",
    "            #print('layer_input after add bias \\n',type(layer_input),layer_input.shape)\n",
    "            \n",
    "            #layer_input = layer_input.reshape(-1,1)\n",
    "            #layer_weights = self.weights[layer_index].reshape(-1,1)\n",
    "            #print('layer_weights shape',layer_weights.transpose().shape,'layer_input shape' , layer_input.shape)\n",
    "            layers_input[layer_index] = layer_input\n",
    "            #print('layers_input in layer_index ',layer_index ,'layer_input shape',layer_input.shape)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_input \\n', layer_input,'shape', layer_input.shape)\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_weights \\n', layer_weights)\n",
    "            #print(layer_input.shape)                       \n",
    "            layers_net[layer_index + 1] = self.net(layer_input,layer_weights)\n",
    "            #print('[foward_propagation] next layer_index',layer_index + 1, ' layers_net ', layers_net[layer_index + 1])\n",
    "                   \n",
    "            layer_output = self.sigmoid(layers_net[layer_index + 1])\n",
    "            \n",
    "            #print('[foward_propagation] sigmoid',layer_index + 1, ' layer_output ',layer_output)\n",
    "            \n",
    "            layer_input = layer_output\n",
    "\n",
    "        layers_input[self.n_layers - 1] = layer_output #p.c_[ layer_output, np.ones((n_examples,1))]   \n",
    "        #print('[foward_propagation] layers_input \\n',layers_input)\n",
    "        return layers_input, layers_net\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        print('[predict]  self.weights',self.weights ,end='\\n\\n') \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        Y_hat = layers_input[-1]\n",
    "        return Y_hat\n",
    "    \n",
    "    def net(self,X,W):\n",
    "        print('net', X.shape,W.transpose().shape)\n",
    "        print('net', X,W.transpose())\n",
    "        return np.dot(X,W.transpose())\n",
    "    \n",
    "    def sigmoid(self,value):\n",
    "        sig = 1 / (1 + np.exp(-value))\n",
    "        return sig     \n",
    " \n",
    "    def error_part(self, value):\n",
    "        error_part = value * (1 - value) \n",
    "        return error_part\n",
    "    \n",
    "    def sigma(self, E,W):\n",
    "        return np.dot(E,W)\n",
    "   \n",
    " \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame([[1,0],[1,0]])\n",
    "#print(X.values)\n",
    "\n",
    "y = pd.DataFrame([1],[1])\n",
    "#print(y.values.shape)\n",
    "# for idx, j in enumerate(X.values):\n",
    "#     #print (X.values[index],y.values[index])\n",
    "#     print(idx,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-091823b3ee57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[784, 784, 10] #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#mlp.train(X_train, y_train,n_iter=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-772691a7f63e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, n_iter)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#print('train it',it)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "mlp = MLPerceptron(layers_len = [2,3,2,1],eta=0.5,random_state=50) #[784, 784, 10] #\n",
    "\n",
    "mlp.train(X.values, y.values,n_iter=1)   \n",
    "mlp.predict(X.values)\n",
    "#mlp.train(X_train, y_train,n_iter=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
