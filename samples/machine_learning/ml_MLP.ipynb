{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import  StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_path = 'mnist-original.mat'\n",
    "\n",
    "mnist = loadmat(mnist_path)\n",
    "X = mnist['data'].T\n",
    "y = mnist['label'][0]\n",
    "#display(X.shape , y.shape)\n",
    "\n",
    "# Scale all X values\n",
    "scaler = StandardScaler()\n",
    "X_scaled  = scaler.fit_transform(X)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.0005,train_size=0.0005, random_state=0)\n",
    "train_index, test_index = next(sss.split(X=X_scaled, y=y))   \n",
    "\n",
    "X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "#display(y_train[:5])\n",
    "df_y_train = pd.get_dummies(y_train)\n",
    "y_train = df_y_train.values\n",
    "#display(y_train[:5])\n",
    "\n",
    "df_y_test = pd.get_dummies(y_test)\n",
    "y_test = df_y_test.values\n",
    "\n",
    "\n",
    "display('X_train shape ', X_train.shape,'X_test shape' , X_test.shape)\n",
    "display('Y_train shape ', y_train.shape,'Y_test shape' , y_test.shape)\n",
    "display(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPerceptron(BaseEstimator):\n",
    "    \n",
    "    #layers - includes input, #hidden, output\n",
    "    def __init__(self,layers_len,eta=0,random_state=50):\n",
    "        self.random_state = random_state\n",
    "        self.eta = eta\n",
    "        self.n_layers = len(layers_len)\n",
    "        self.layers_len = layers_len\n",
    "       \n",
    "        self.init_weights()\n",
    "     \n",
    "    \n",
    "    def init_weights(self):\n",
    "        rng = np.random.RandomState(self.random_state)       \n",
    "                \n",
    "        layers_len_next = self.layers_len.copy()\n",
    "        self.weights = []\n",
    "        layers_len_next.pop(0)\n",
    "        \n",
    "        #print(self.layers_len)\n",
    "        \n",
    "#         for layer_len, layer_len_next in zip(self.layers_len, layers_len_next):\n",
    "#             #print(layer_len,layer_len_next)\n",
    "                        \n",
    "#             w = rng.normal(loc=0.0,scale=0.1,size=[layer_len_next,layer_len + 1])\n",
    "#             #print('w',w)\n",
    "            \n",
    "#             self.weights.append(w)\n",
    "        \n",
    "        '''\n",
    "        for debug the sample page 376\n",
    "        '''\n",
    "        self.weights.append(np.array([[0.5, 0, 0.3],\n",
    "                                   [-0.2, 0.4, 0.7],\n",
    "                                   [0,-0.5, -0.1]]))\n",
    "        self.weights.append(np.array([[-0.5, 0.4, 0,0],\n",
    "                                   [0.3, 0.6, 0.4,0]]))\n",
    "        self.weights.append(np.array([[0.5, 0.7, 0]]))\n",
    "                            \n",
    "        \n",
    "        #print('weights', self.weights)\n",
    "        return self.weights\n",
    "    \n",
    "    def train(self,X,y,n_iter=50):\n",
    "    \n",
    "        n_samples = y.shape[0]\n",
    "        #print('n_iter',n_iter)\n",
    "        \n",
    "        for it in range(n_iter):\n",
    "            #print('train it',it)\n",
    "            self.back_propagation(X, y)\n",
    "           \n",
    "            \n",
    "    def back_propagation(self, X,y):\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        print('x shape',n_samples)\n",
    "    \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        #print('[back_propagation] layers_net \\n',layers_net,end='\\n\\n')\n",
    "        #print('[back_propagation] layers_input \\n',layers_input,end='\\n\\n')\n",
    "            \n",
    "        errors = [None] * self.n_layers\n",
    "        sigmas = [None] * self.n_layers\n",
    "        \n",
    "#         print('[back_propagation] errors[-1] before ',layers_input[-1].shape)\n",
    "#         print('[back_propagation] errors[-1] before ',y.shape)\n",
    "        errors[-1] = (layers_input[-1] - y) * self.error_part(layers_input[-1])\n",
    "        #print('[back_propagation] errors[-1]  after',errors)\n",
    "            \n",
    "        for layer_index in np.arange(self.n_layers - 2  ,0 , -1):\n",
    "            #print('[back_propagation] LAYER ',layer_index)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_weights = np.delete(layer_weights, -1, axis=1) #remove weight for bias\n",
    "            #print('[back_propagation] layer_weights after remove bias \\n',layer_weights,end='\\n\\n')  \n",
    "            \n",
    "            sigmas[layer_index] = self.sigma(errors[layer_index+1],layer_weights)\n",
    "            #print('[back_propagation] sigmas \\n', sigmas[layer_index],end='\\n\\n') \n",
    "                       \n",
    "            layer_input = layers_input[layer_index]\n",
    "            layer_input = np.delete(layer_input, -1, axis=1)\n",
    "            #print('[back_propagation] layer_input after remove bias',layer_input,end='\\n\\n')\n",
    "            \n",
    "            errors[layer_index] =  sigmas[layer_index] * self.error_part(layer_input)\n",
    "            #print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "        \n",
    "        print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "            \n",
    "            \n",
    "        #update weights\n",
    "        #print('[back_propagation] UPDATE WEIGHTS' ,end='\\n\\n') \n",
    "        tmp_weights = [None] * self.n_layers\n",
    "        for layer_index in np.arange(self.n_layers - 1):\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_input = layers_input[layer_index]\n",
    "                                         \n",
    "            print('[back_propagation] layer_weights',layer_weights ,end='\\n\\n') \n",
    "            print('[back_propagation] layer_input',layer_input ,end='\\n\\n') \n",
    "            print(errors[layer_index+1].transpose())\n",
    "           \n",
    "            print('errors transpose', errors[layer_index+1].transpose().shape,'layer_input reshape [sample,]',\n",
    "                  layer_input.reshape(-1,1).shape ,end='\\n\\n') \n",
    "#       self.layers_len[layer_index]+1,n_samples\n",
    "            \n",
    "            tmp_weights =  np.dot(errors[layer_index+1].transpose(), layer_input.reshape(-1,1).transpose())\n",
    "            print('[back_propagation] tmp_weights',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            tmp_weights =  tmp_weights * self.eta\n",
    "            print('[back_propagation] tmp_weights * eta',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            self.weights[layer_index]  = self.weights[layer_index] - tmp_weights\n",
    "            print('[back_propagation]  comp weights',self.weights[layer_index] ,end='\\n\\n') \n",
    "        \n",
    "        \n",
    "        print('[back_propagation]  self.weights',self.weights ,end='\\n\\n') \n",
    "       \n",
    "      \n",
    "        \n",
    "    def foward_propagation(self, X):\n",
    "        \n",
    "        #print('[foward_propagation] n_layers',self.n_layers)\n",
    "        \n",
    "        layers_input = [None] * self.n_layers\n",
    "        layers_net = [None] * self.n_layers\n",
    "        \n",
    "        \n",
    "        layer_input = X\n",
    "        #print('[foward_propagation] layer_input \\n',layer_input)\n",
    "        \n",
    "        layers_net[0] = np.array(layer_input.ravel())\n",
    "        for layer_index in range(self.n_layers - 1):\n",
    "            #print('foward_propagation layer_index',layer_index)\n",
    "            n_examples = layer_input.shape[0]\n",
    "            #print('n_examples',n_examples,'layer_input',layer_input.shape)\n",
    "            layer_input = np.c_[ layer_input, np.ones((n_examples,1))]  \n",
    "            #print('layer_input after add bias \\n',type(layer_input),layer_input.shape)\n",
    "            \n",
    "            #layer_input = layer_input.reshape(-1,1)\n",
    "            #layer_weights = self.weights[layer_index].reshape(-1,1)\n",
    "            #print('layer_weights shape',layer_weights.transpose().shape,'layer_input shape' , layer_input.shape)\n",
    "            layers_input[layer_index] = layer_input\n",
    "            #print('layers_input in layer_index ',layer_index ,'layer_input shape',layer_input.shape)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_input \\n', layer_input,'shape', layer_input.shape)\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_weights \\n', layer_weights)\n",
    "            #print(layer_input.shape)                       \n",
    "            layers_net[layer_index + 1] = self.net(layer_input,layer_weights)\n",
    "            #print('[foward_propagation] next layer_index',layer_index + 1, ' layers_net ', layers_net[layer_index + 1])\n",
    "                   \n",
    "            layer_output = self.sigmoid(layers_net[layer_index + 1])\n",
    "            \n",
    "            #print('[foward_propagation] sigmoid',layer_index + 1, ' layer_output ',layer_output)\n",
    "            \n",
    "            layer_input = layer_output\n",
    "\n",
    "        layers_input[self.n_layers - 1] = layer_output #p.c_[ layer_output, np.ones((n_examples,1))]   \n",
    "        #print('[foward_propagation] layers_input \\n',layers_input)\n",
    "        return layers_input, layers_net\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        print('[predict]  self.weights',self.weights ,end='\\n\\n') \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        Y_hat = layers_input[-1]\n",
    "        return Y_hat\n",
    "    \n",
    "    def net(self,X,W):\n",
    "        #print('net', X.shape,W.transpose().shape)\n",
    "        #print('net', X,W.transpose())\n",
    "        return np.dot(X,W.transpose())\n",
    "    \n",
    "    def sigmoid(self,value):\n",
    "        sig = 1 / (1 + np.exp(-value))\n",
    "        return sig     \n",
    " \n",
    "    def error_part(self, value):\n",
    "        error_part = value * (1 - value) \n",
    "        return error_part\n",
    "    \n",
    "    def sigma(self, E,W):\n",
    "        return np.dot(E,W)\n",
    "   \n",
    " \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame([[1,0]])\n",
    "print(X.values.shape)\n",
    "y = pd.DataFrame([1])\n",
    "print(y.values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape 1\n",
      "[back_propagation] errors \n",
      " [None, array([[ 0.00026211, -0.00239258, -0.00109259]]), array([[-0.00902267, -0.01095328]]), array([[-0.07234781]])]\n",
      "\n",
      "[back_propagation] layer_weights [[ 0.5  0.   0.3]\n",
      " [-0.2  0.4  0.7]\n",
      " [ 0.  -0.5 -0.1]]\n",
      "\n",
      "[back_propagation] layer_input [[1. 0. 1.]]\n",
      "\n",
      "[[ 0.00026211]\n",
      " [-0.00239258]\n",
      " [-0.00109259]]\n",
      "errors transpose (3, 1) layer_input reshape [sample,] (3, 1)\n",
      "\n",
      "[back_propagation] tmp_weights [[ 0.00026211  0.          0.00026211]\n",
      " [-0.00239258 -0.         -0.00239258]\n",
      " [-0.00109259 -0.         -0.00109259]]\n",
      "\n",
      "[back_propagation] tmp_weights * eta [[ 0.00013106  0.          0.00013106]\n",
      " [-0.00119629 -0.         -0.00119629]\n",
      " [-0.0005463  -0.         -0.0005463 ]]\n",
      "\n",
      "[back_propagation]  comp weights [[ 4.99868943e-01  0.00000000e+00  2.99868943e-01]\n",
      " [-1.98803709e-01  4.00000000e-01  7.01196291e-01]\n",
      " [ 5.46297328e-04 -5.00000000e-01 -9.94537027e-02]]\n",
      "\n",
      "[back_propagation] layer_weights [[-0.5  0.4  0.   0. ]\n",
      " [ 0.3  0.6  0.4  0. ]]\n",
      "\n",
      "[back_propagation] layer_input [[0.68997448 0.62245933 0.47502081 1.        ]]\n",
      "\n",
      "[[-0.00902267]\n",
      " [-0.01095328]]\n",
      "errors transpose (2, 1) layer_input reshape [sample,] (4, 1)\n",
      "\n",
      "[back_propagation] tmp_weights [[-0.00622541 -0.00561625 -0.00428596 -0.00902267]\n",
      " [-0.00755749 -0.00681797 -0.00520304 -0.01095328]]\n",
      "\n",
      "[back_propagation] tmp_weights * eta [[-0.00311271 -0.00280812 -0.00214298 -0.00451134]\n",
      " [-0.00377874 -0.00340899 -0.00260152 -0.00547664]]\n",
      "\n",
      "[back_propagation]  comp weights [[-0.49688729  0.40280812  0.00214298  0.00451134]\n",
      " [ 0.30377874  0.60340899  0.40260152  0.00547664]]\n",
      "\n",
      "[back_propagation] layer_weights [[0.5 0.7 0. ]]\n",
      "\n",
      "[back_propagation] layer_input [[0.47601754 0.68362391 1.        ]]\n",
      "\n",
      "[[-0.07234781]]\n",
      "errors transpose (1, 1) layer_input reshape [sample,] (3, 1)\n",
      "\n",
      "[back_propagation] tmp_weights [[-0.03443883 -0.0494587  -0.07234781]]\n",
      "\n",
      "[back_propagation] tmp_weights * eta [[-0.01721941 -0.02472935 -0.03617391]]\n",
      "\n",
      "[back_propagation]  comp weights [[0.51721941 0.72472935 0.03617391]]\n",
      "\n",
      "[back_propagation]  self.weights [array([[ 4.99868943e-01,  0.00000000e+00,  2.99868943e-01],\n",
      "       [-1.98803709e-01,  4.00000000e-01,  7.01196291e-01],\n",
      "       [ 5.46297328e-04, -5.00000000e-01, -9.94537027e-02]]), array([[-0.49688729,  0.40280812,  0.00214298,  0.00451134],\n",
      "       [ 0.30377874,  0.60340899,  0.40260152,  0.00547664]]), array([[0.51721941, 0.72472935, 0.03617391]])]\n",
      "\n",
      "[predict]  self.weights [array([[ 4.99868943e-01,  0.00000000e+00,  2.99868943e-01],\n",
      "       [-1.98803709e-01,  4.00000000e-01,  7.01196291e-01],\n",
      "       [ 5.46297328e-04, -5.00000000e-01, -9.94537027e-02]]), array([[-0.49688729,  0.40280812,  0.00214298,  0.00451134],\n",
      "       [ 0.30377874,  0.60340899,  0.40260152,  0.00547664]]), array([[0.51721941, 0.72472935, 0.03617391]])]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.68588005]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPerceptron(layers_len = [2,3,2,1],eta=0.5,random_state=50) #[784, 784, 10] #\n",
    "\n",
    "mlp.train(X.values, y.values,n_iter=1)   \n",
    "mlp.predict(X.values)\n",
    "#mlp.train(X_train, y_train,n_iter=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
