{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import  StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_path = 'mnist-original.mat'\n",
    "\n",
    "mnist = loadmat(mnist_path)\n",
    "X = mnist['data'].T\n",
    "y = mnist['label'][0]\n",
    "#display(X.shape , y.shape)\n",
    "\n",
    "# Scale all X values\n",
    "scaler = StandardScaler()\n",
    "X_scaled  = scaler.fit_transform(X)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.0005,train_size=0.0005, random_state=0)\n",
    "train_index, test_index = next(sss.split(X=X_scaled, y=y))   \n",
    "\n",
    "X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "#display(y_train[:5])\n",
    "df_y_train = pd.get_dummies(y_train)\n",
    "y_train = df_y_train.values\n",
    "#display(y_train[:5])\n",
    "\n",
    "df_y_test = pd.get_dummies(y_test)\n",
    "y_test = df_y_test.values\n",
    "\n",
    "\n",
    "display('X_train shape ', X_train.shape,'X_test shape' , X_test.shape)\n",
    "display('Y_train shape ', y_train.shape,'Y_test shape' , y_test.shape)\n",
    "display(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPerceptron(BaseEstimator):\n",
    "    \n",
    "    #layers - includes input, #hidden, output\n",
    "    def __init__(self,layers_len,eta=0,random_state=50):\n",
    "        self.random_state = random_state\n",
    "        self.eta = eta\n",
    "        self.n_layers = len(layers_len)\n",
    "        self.layers_len = layers_len\n",
    "       \n",
    "        self.init_weights()\n",
    "     \n",
    "    \n",
    "    def init_weights(self):\n",
    "        rng = np.random.RandomState(self.random_state)       \n",
    "                \n",
    "        layers_len_next = self.layers_len.copy()\n",
    "        self.weights = []\n",
    "        layers_len_next.pop(0)\n",
    "        \n",
    "        #print(self.layers_len)\n",
    "        \n",
    "#         for layer_len, layer_len_next in zip(self.layers_len, layers_len_next):\n",
    "#             #print(layer_len,layer_len_next)\n",
    "                        \n",
    "#             w = rng.normal(loc=0.0,scale=0.1,size=[layer_len_next,layer_len + 1])\n",
    "#             #print('w',w)\n",
    "            \n",
    "#             self.weights.append(w)\n",
    "        \n",
    "        '''\n",
    "        for debug the sample page 376\n",
    "        '''\n",
    "        self.weights.append(np.array([[0.5, 0, 0.3],\n",
    "                                   [-0.2, 0.4, 0.7],\n",
    "                                   [0,-0.5, -0.1]]))\n",
    "        self.weights.append(np.array([[-0.5, 0.4, 0,0],\n",
    "                                   [0.3, 0.6, 0.4,0]]))\n",
    "        self.weights.append(np.array([[0.5, 0.7, 0]]))\n",
    "                            \n",
    "        \n",
    "        #print('weights', self.weights)\n",
    "        return self.weights\n",
    "    \n",
    "    def train(self,X,y,n_iter=50):\n",
    "    \n",
    "        n_samples = y.shape[0]\n",
    "        #print('n_iter',n_iter)\n",
    "        \n",
    "        for it in range(n_iter):\n",
    "            #print('train it',it)\n",
    "             for idx, sample in enumerate(X.values):\n",
    "                #print('sample',sample)\n",
    "                self.back_propagation(sample, y[idx])\n",
    "            \n",
    "           \n",
    "            \n",
    "    def back_propagation(self, X,y):\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        #print('x shape',n_samples)\n",
    "    \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        #print('[back_propagation] layers_net \\n',layers_net,end='\\n\\n')\n",
    "        #print('[back_propagation] layers_input \\n',layers_input,end='\\n\\n')\n",
    "            \n",
    "        errors = [None] * self.n_layers\n",
    "        sigmas = [None] * self.n_layers\n",
    "        \n",
    "#         print('[back_propagation] errors[-1] before ',layers_input[-1].shape)\n",
    "#         print('[back_propagation] errors[-1] before ',y.shape)\n",
    "        errors[-1] = (layers_input[-1] - y) * self.error_part(layers_input[-1])\n",
    "        #print('[back_propagation] errors[-1]  after',errors)\n",
    "            \n",
    "        for layer_index in np.arange(self.n_layers - 2  ,0 , -1):\n",
    "            #print('[back_propagation] LAYER ',layer_index)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_weights = np.delete(layer_weights, -1, axis=1) #remove weight for bias\n",
    "            #print('[back_propagation] layer_weights after remove bias \\n',layer_weights,end='\\n\\n')  \n",
    "            \n",
    "            sigmas[layer_index] = self.sigma(errors[layer_index+1],layer_weights)\n",
    "            #print('[back_propagation] sigmas \\n', sigmas[layer_index],end='\\n\\n') \n",
    "                       \n",
    "            layer_input = layers_input[layer_index]\n",
    "            #print('[back_propagation] layer_input before delete',layer_input,end='\\n\\n')\n",
    "            #layer_input = np.delete(layer_input, -1, axis=1)\n",
    "            layer_input = np.delete(layer_input, -1)\n",
    "            #print('[back_propagation] layer_input after remove bias',layer_input,end='\\n\\n')\n",
    "            \n",
    "            errors[layer_index] =  sigmas[layer_index] * self.error_part(layer_input)\n",
    "            #print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "        \n",
    "        print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "            \n",
    "            \n",
    "        #update weights\n",
    "        #print('[back_propagation] UPDATE WEIGHTS' ,end='\\n\\n') \n",
    "        tmp_weights = [None] * self.n_layers\n",
    "        for layer_index in np.arange(self.n_layers - 1):\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_input = layers_input[layer_index]\n",
    "                                         \n",
    "            print('[back_propagation] layer_weights',layer_weights ,end='\\n\\n') \n",
    "            print('[back_propagation] layer_input',layer_input ,end='\\n\\n') \n",
    "           \n",
    "           \n",
    "            \n",
    "#       self.layers_len[layer_index]+1,n_samples\n",
    "            print('[back_propagation] errors[layer_index+1]' , errors[layer_index+1].shape)\n",
    "            print('[back_propagation] layer_input.transpose()' , layer_input.reshape(-1,1).shape)\n",
    "            tmp_weights =  np.dot(errors[layer_index+1].reshape(-1,1), layer_input.reshape(-1,1))\n",
    "            print('[back_propagation] tmp_weights',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            tmp_weights =  tmp_weights * self.eta\n",
    "            print('[back_propagation] tmp_weights * eta',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            self.weights[layer_index]  = self.weights[layer_index] - tmp_weights\n",
    "            print('[back_propagation]  comp weights',self.weights[layer_index] ,end='\\n\\n') \n",
    "        \n",
    "        \n",
    "        print('[back_propagation]  self.weights',self.weights ,end='\\n\\n') \n",
    "       \n",
    "      \n",
    "        \n",
    "    def foward_propagation(self, X):\n",
    "        \n",
    "        #print('[foward_propagation] n_layers',self.n_layers)\n",
    "        \n",
    "        layers_input = [None] * self.n_layers\n",
    "        layers_net = [None] * self.n_layers\n",
    "        \n",
    "        \n",
    "        layer_input = X\n",
    "        #print('[foward_propagation] layer_input \\n',layer_input,type(layer_input))\n",
    "        \n",
    "        \n",
    "        layers_net[0] = np.array(layer_input.ravel())\n",
    "        for layer_index in range(self.n_layers - 1):\n",
    "            #print('foward_propagation layer_index',layer_index)\n",
    "            n_examples = layer_input.shape[0]\n",
    "            #print('n_examples',n_examples,'layer_input',layer_input.T)\n",
    "            #layer_input = np.c_[layer_input, np.array([1])] #np.ones((n_examples,1))] \n",
    "            layer_input = np.concatenate((np.array(layer_input), np.array([1])))\n",
    "            #print('layer_input after add bias \\n',type(layer_input),layer_input.shape)\n",
    "            #print('layer_input',layer_input)\n",
    "            \n",
    "            #layer_input = layer_input.reshape(-1,1)\n",
    "            #layer_weights = self.weights[layer_index].reshape(-1,1)\n",
    "            #print('layer_weights shape',layer_weights.transpose().shape,'layer_input shape' , layer_input.shape)\n",
    "            layers_input[layer_index] = layer_input\n",
    "            #print('layers_input in layer_index ',layer_index ,'layer_input shape',layer_input.shape)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_input \\n', layer_input,'shape', layer_input.shape)\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_weights \\n', layer_weights)\n",
    "            print(layer_input.shape,layer_weights.shape)                       \n",
    "            layers_net[layer_index + 1] = self.net(layer_input,layer_weights)\n",
    "            #print('[foward_propagation] next layer_index',layer_index + 1, ' layers_net ', layers_net[layer_index + 1])\n",
    "                   \n",
    "            layer_output = self.sigmoid(layers_net[layer_index + 1])\n",
    "            \n",
    "            #print('[foward_propagation] sigmoid',layer_index + 1, ' layer_output ',layer_output)\n",
    "            \n",
    "            layer_input = layer_output\n",
    "\n",
    "        layers_input[self.n_layers - 1] = layer_output #p.c_[ layer_output, np.ones((n_examples,1))]   \n",
    "        #print('[foward_propagation] layers_input \\n',layers_input)\n",
    "        return layers_input, layers_net\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        print('[predict]  self.weights',self.weights ,end='\\n\\n') \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        Y_hat = layers_input[-1]\n",
    "        return Y_hat\n",
    "    \n",
    "    def net(self,X,W):\n",
    "        #print('net', X.shape,W.shape)\n",
    "        #print('net', X,W.transpose())\n",
    "        return np.dot(X,W.transpose())\n",
    "    \n",
    "    def sigmoid(self,value):\n",
    "        sig = 1 / (1 + np.exp(-value))\n",
    "        return sig     \n",
    " \n",
    "    def error_part(self, value):\n",
    "        error_part = value * (1 - value) \n",
    "        return error_part\n",
    "    \n",
    "    def sigma(self, E,W):\n",
    "        return np.dot(E,W)\n",
    "   \n",
    " \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.DataFrame([[1,0]])\n",
    "#X2 = pd.DataFrame([[1,0],[1,0]])\n",
    "\n",
    "#print(X.values)\n",
    "# print(X2.values)\n",
    "\n",
    "# for idx, j in enumerate(X):\n",
    "#     #print (X.values[index],y.values[index])\n",
    "#     print(idx,j)\n",
    "    \n",
    "# for idx, j in enumerate(X2):\n",
    "#     #print (X.values[index],y.values[index])\n",
    "#     print(idx,j)\n",
    "\n",
    "y = pd.DataFrame([1])\n",
    "# #y = pd.DataFrame([1],[1])\n",
    "\n",
    "# #print(y.values.shape)\n",
    "# # for idx, j in enumerate(X.values):\n",
    "# #     #print (X.values[index],y.values[index])\n",
    "# #     print(idx,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3,) (3, 3)\n",
      "(4,) (2, 4)\n",
      "(3,) (1, 3)\n",
      "[back_propagation] errors \n",
      " [None, array([ 0.00026211, -0.00239258, -0.00109259]), array([-0.00902267, -0.01095328]), 0   -0.072348\n",
      "Name: 0, dtype: float64]\n",
      "\n",
      "[back_propagation] layer_weights [[ 0.5  0.   0.3]\n",
      " [-0.2  0.4  0.7]\n",
      " [ 0.  -0.5 -0.1]]\n",
      "\n",
      "[back_propagation] layer_input [1 0 1]\n",
      "\n",
      "[back_propagation] errors[layer_index+1] (3,)\n",
      "[back_propagation] layer_input.transpose() (3, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-6bf0293698b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#display(type(X))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#mlp.train(X_train, y_train,n_iter=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-0e1268a80b6f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, n_iter)\u001b[0m\n\u001b[0;32m     51\u001b[0m              \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;31m#print('sample',sample)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-0e1268a80b6f>\u001b[0m in \u001b[0;36mback_propagation\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[back_propagation] errors[layer_index+1]'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[back_propagation] layer_input.transpose()'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlayer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mtmp_weights\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[back_propagation] tmp_weights'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmp_weights\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "mlp = MLPerceptron(layers_len = [2,3,2,1],eta=0.5,random_state=50) #[784, 784, 10] #\n",
    "#display(type(X))\n",
    "print(type(X))\n",
    "mlp.train(X, y,n_iter=1)   \n",
    "mlp.predict(X)\n",
    "#mlp.train(X_train, y_train,n_iter=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-b4f4b55d3dc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "np.c_[np.array([0,1]), np.array([1])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
