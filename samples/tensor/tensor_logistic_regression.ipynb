{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex 552\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "tf.disable_eager_execution()\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "samples,features = housing.data.shape\n",
    "print(samples,features)\n",
    "#housing_data_plus_bias = np.c_[np.ones((samples,1)),housing.data]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_bias = np.c_[np.ones((samples,1)),scaled_housing_data]\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(samples / batch_size))\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None, features + 1),name='X')\n",
    "y = tf.placeholder(tf.float32,shape=(None, 1),name='y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([features + 1,1],-1,1,seed=42),name='theta')\n",
    "\n",
    "\n",
    "# t = np.dot(theta.transpose(),X)\n",
    "# p_hat = 1 / (1 + np.exp(-t)) # sigmoid(t)\n",
    "# # Sigmoid Cross Entropy Cost Function \n",
    "# loss = tf.reduce_mean(-y * np.log(p_hat) - (1 - y) * np.log(1 - p_hat)).mean()\n",
    "\n",
    "b = tf.Variable(tf.zeros([1])) \n",
    "print(X.shape,theta.shape)\n",
    "t = tf.add(tf.matmul(X, theta), b) \n",
    "Y_hat = tf.nn.sigmoid(t) \n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = Y_hat, labels = y) \n",
    "\n",
    "gradients_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "traning_op = gradients_optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    indices = np.random.randint(samples,size=batch_size)\n",
    "    x_batch = scaled_housing_data_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return x_batch,y_batch\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print ('epoch',epoch,'loss = ',\n",
    "               loss.eval(feed_dict={X: scaled_housing_data_bias,\n",
    "                                   y: housing.target.reshape(-1,1)}))\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_index,batch_size)\n",
    "            sess.run(traning_op,feed_dict={X: X_batch,y: y_batch})\n",
    "        \n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print('best_theta')\n",
    "print(best_theta)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test [0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "1437\n",
      "(None, 65) (65, 1)\n",
      "(65, 1)\n",
      "[[7.87404776e-02]\n",
      " [3.83186340e-03]\n",
      " [8.39230418e-03]\n",
      " [1.59344405e-01]\n",
      " [6.06247783e-03]\n",
      " [2.11256474e-01]\n",
      " [4.63724136e-05]\n",
      " [2.74428725e-03]\n",
      " [3.87293100e-03]\n",
      " [3.05237770e-02]\n",
      " [8.57577503e-01]\n",
      " [8.28970492e-01]\n",
      " [1.34127736e-02]\n",
      " [9.04785454e-01]\n",
      " [1.62649155e-03]\n",
      " [3.43756378e-02]\n",
      " [4.37051058e-04]\n",
      " [6.99872375e-02]\n",
      " [5.71578741e-04]\n",
      " [9.92822647e-03]\n",
      " [7.94798136e-04]\n",
      " [4.30961847e-02]\n",
      " [5.21480441e-02]\n",
      " [5.21838665e-04]\n",
      " [9.26757812e-01]\n",
      " [8.81254673e-05]\n",
      " [3.40947509e-03]\n",
      " [2.13921070e-03]\n",
      " [4.15714681e-02]\n",
      " [6.72414601e-02]\n",
      " [3.38013172e-02]\n",
      " [1.10246241e-02]\n",
      " [1.98088914e-01]\n",
      " [1.79010630e-03]\n",
      " [6.39390945e-03]\n",
      " [4.61694598e-03]\n",
      " [5.98260760e-03]\n",
      " [2.43583322e-03]\n",
      " [5.56349754e-04]\n",
      " [3.73864174e-02]\n",
      " [2.32750177e-03]\n",
      " [4.88165021e-03]\n",
      " [8.68070722e-02]\n",
      " [2.31981277e-04]\n",
      " [4.76142764e-03]\n",
      " [5.35935163e-04]\n",
      " [5.76679409e-02]\n",
      " [8.03706050e-03]\n",
      " [9.08112526e-03]\n",
      " [8.64124596e-02]\n",
      " [8.63555074e-03]\n",
      " [3.25248539e-02]\n",
      " [7.24407971e-01]\n",
      " [9.79962945e-03]\n",
      " [1.09606683e-02]\n",
      " [2.10627317e-02]\n",
      " [2.02104449e-03]\n",
      " [1.43194199e-03]\n",
      " [5.61118126e-04]\n",
      " [3.14072967e-02]\n",
      " [3.88076901e-03]\n",
      " [8.97586346e-04]\n",
      " [2.62828469e-01]\n",
      " [2.77850926e-02]\n",
      " [3.76105309e-03]\n",
      " [1.01594031e-02]\n",
      " [3.43769789e-04]\n",
      " [1.25443935e-03]\n",
      " [9.68030095e-03]\n",
      " [6.79165125e-04]\n",
      " [3.32409143e-03]\n",
      " [1.07342005e-03]\n",
      " [5.52818179e-02]\n",
      " [4.35322523e-04]\n",
      " [3.97503376e-04]\n",
      " [6.69002533e-03]\n",
      " [5.21212816e-04]\n",
      " [8.44389200e-04]\n",
      " [4.86084819e-03]\n",
      " [2.85658240e-03]\n",
      " [9.48719203e-01]\n",
      " [4.30196524e-04]\n",
      " [4.85837460e-04]\n",
      " [5.96654415e-03]\n",
      " [1.24669075e-03]\n",
      " [8.18824768e-03]\n",
      " [6.28654063e-02]\n",
      " [6.46916926e-01]\n",
      " [2.36648321e-02]\n",
      " [1.71589851e-02]\n",
      " [9.57463980e-02]\n",
      " [7.00575113e-03]\n",
      " [2.99727023e-02]\n",
      " [7.08264410e-02]\n",
      " [2.39218473e-02]\n",
      " [7.50605702e-01]\n",
      " [7.75679052e-02]\n",
      " [6.54816628e-04]\n",
      " [9.66684461e-01]\n",
      " [7.38644600e-03]\n",
      " [6.35394454e-03]\n",
      " [2.17273831e-03]\n",
      " [2.87332237e-02]\n",
      " [2.46044993e-03]\n",
      " [1.08274817e-02]\n",
      " [2.57810056e-02]\n",
      " [1.99655890e-02]\n",
      " [4.94092703e-04]\n",
      " [1.23523176e-02]\n",
      " [5.22792339e-04]\n",
      " [4.36082184e-02]\n",
      " [1.38908625e-04]\n",
      " [5.54574728e-02]\n",
      " [7.57930994e-01]\n",
      " [4.74452972e-05]\n",
      " [3.49944830e-03]\n",
      " [6.69845939e-03]\n",
      " [9.19770598e-02]\n",
      " [2.61056423e-03]\n",
      " [9.54714417e-03]\n",
      " [8.39581788e-02]\n",
      " [8.19635391e-03]\n",
      " [5.22781312e-02]\n",
      " [4.54299927e-01]\n",
      " [3.73482704e-04]\n",
      " [7.77536631e-03]\n",
      " [3.52000594e-02]\n",
      " [3.30901146e-03]\n",
      " [4.44684476e-01]\n",
      " [2.27114558e-03]\n",
      " [2.65669227e-02]\n",
      " [9.68677878e-01]\n",
      " [9.06795263e-04]\n",
      " [2.71767378e-04]\n",
      " [2.49862671e-03]\n",
      " [2.93627441e-01]\n",
      " [5.43510914e-03]\n",
      " [8.88806581e-03]\n",
      " [6.07348502e-01]\n",
      " [9.72985029e-01]\n",
      " [2.63154507e-05]\n",
      " [5.33873558e-01]\n",
      " [1.04698241e-02]\n",
      " [5.82346380e-01]\n",
      " [7.07507133e-05]\n",
      " [4.17822003e-02]\n",
      " [2.91526318e-04]\n",
      " [2.00742483e-03]\n",
      " [2.66760588e-04]\n",
      " [3.87161970e-04]\n",
      " [4.19080257e-04]\n",
      " [9.75912809e-03]\n",
      " [9.15058374e-01]\n",
      " [6.54160976e-05]\n",
      " [1.28564239e-03]\n",
      " [1.80661678e-04]\n",
      " [2.04576850e-02]\n",
      " [1.20588511e-01]\n",
      " [4.16764617e-03]\n",
      " [2.44067013e-02]\n",
      " [1.03765726e-03]\n",
      " [2.05278397e-04]\n",
      " [7.52925873e-04]\n",
      " [5.27441502e-04]\n",
      " [3.35693359e-04]\n",
      " [5.22622466e-03]\n",
      " [6.94996119e-03]\n",
      " [4.72664833e-04]\n",
      " [3.44645977e-03]\n",
      " [3.10885906e-03]\n",
      " [1.22448474e-01]\n",
      " [1.15510821e-03]\n",
      " [2.59280205e-04]\n",
      " [2.82466412e-04]\n",
      " [2.74577737e-03]\n",
      " [2.83252239e-01]\n",
      " [1.37656927e-04]\n",
      " [9.46115494e-01]\n",
      " [3.31106782e-03]\n",
      " [1.30781531e-03]\n",
      " [7.28975773e-01]\n",
      " [2.25179940e-01]\n",
      " [2.04175711e-04]\n",
      " [1.03030205e-02]\n",
      " [1.59442425e-04]\n",
      " [1.28298998e-04]\n",
      " [7.43895769e-04]\n",
      " [3.74375284e-02]\n",
      " [1.11939609e-02]\n",
      " [1.79588795e-04]\n",
      " [1.80748105e-03]\n",
      " [5.00619411e-04]\n",
      " [5.48869371e-04]\n",
      " [6.39438629e-04]\n",
      " [2.32934952e-04]\n",
      " [3.70615125e-02]\n",
      " [2.67809033e-02]\n",
      " [1.49160624e-04]\n",
      " [6.14404678e-04]\n",
      " [1.87456608e-05]\n",
      " [1.79994404e-02]\n",
      " [3.12632322e-03]\n",
      " [3.89108062e-03]\n",
      " [1.66535378e-04]\n",
      " [5.90887666e-03]\n",
      " [1.28545165e-02]\n",
      " [8.36962342e-01]\n",
      " [1.10801458e-02]\n",
      " [4.75764275e-04]\n",
      " [3.27914953e-03]\n",
      " [2.71297693e-02]\n",
      " [3.95059586e-04]\n",
      " [2.39610672e-05]\n",
      " [9.14645672e-01]\n",
      " [1.15951002e-02]\n",
      " [7.17118382e-03]\n",
      " [3.67522240e-04]\n",
      " [3.14170122e-03]\n",
      " [1.10850602e-01]\n",
      " [6.15996897e-01]\n",
      " [5.37567437e-02]\n",
      " [1.47311687e-02]\n",
      " [8.57360005e-01]\n",
      " [6.41673803e-04]\n",
      " [5.02675772e-03]\n",
      " [1.93494558e-02]\n",
      " [2.65226066e-02]\n",
      " [2.66230106e-03]\n",
      " [1.60666615e-01]\n",
      " [4.24474478e-04]\n",
      " [4.34612334e-02]\n",
      " [4.38633263e-02]\n",
      " [1.33191943e-02]\n",
      " [2.11355090e-03]\n",
      " [3.13520432e-05]\n",
      " [9.72728252e-01]\n",
      " [4.40549850e-03]\n",
      " [3.43680382e-04]\n",
      " [1.70192122e-03]\n",
      " [8.20428133e-04]\n",
      " [1.44701898e-02]\n",
      " [1.55031681e-04]\n",
      " [1.15731359e-03]\n",
      " [2.25189328e-03]\n",
      " [9.72479582e-03]\n",
      " [9.69890118e-01]\n",
      " [5.49924374e-03]\n",
      " [3.41147184e-04]\n",
      " [5.60166836e-02]\n",
      " [4.21822071e-03]\n",
      " [4.27691936e-02]\n",
      " [3.59939337e-02]\n",
      " [6.49806857e-03]\n",
      " [1.17044270e-01]\n",
      " [7.97802210e-03]\n",
      " [7.77208567e-01]\n",
      " [1.48572028e-02]\n",
      " [1.45256519e-04]\n",
      " [3.52185965e-03]\n",
      " [5.10899425e-02]\n",
      " [3.22447717e-02]\n",
      " [2.70019174e-02]\n",
      " [9.76246893e-01]\n",
      " [9.86924469e-01]\n",
      " [1.14918053e-02]\n",
      " [8.91288757e-01]\n",
      " [1.15200877e-02]\n",
      " [2.30599940e-02]\n",
      " [2.61555016e-02]\n",
      " [1.60617232e-02]\n",
      " [7.86158741e-02]\n",
      " [1.02695823e-03]\n",
      " [1.42908096e-03]\n",
      " [1.02055073e-03]\n",
      " [6.36279583e-04]\n",
      " [8.11442733e-03]\n",
      " [9.73768294e-01]\n",
      " [1.34527683e-04]\n",
      " [2.48087615e-01]\n",
      " [3.94794345e-03]\n",
      " [3.49301994e-02]\n",
      " [2.69751459e-01]\n",
      " [2.91615725e-04]\n",
      " [8.73124599e-03]\n",
      " [2.00184941e-01]\n",
      " [2.37475634e-02]\n",
      " [6.40320778e-03]\n",
      " [4.51698661e-01]\n",
      " [4.03848290e-03]\n",
      " [1.39018893e-03]\n",
      " [4.03225422e-03]\n",
      " [3.16202641e-05]\n",
      " [2.08413303e-02]\n",
      " [1.93747878e-03]\n",
      " [9.87023115e-04]\n",
      " [1.55537426e-02]\n",
      " [3.09267640e-03]\n",
      " [2.94678509e-02]\n",
      " [1.01923943e-05]\n",
      " [2.16311216e-03]\n",
      " [1.08388066e-03]\n",
      " [9.37961221e-01]\n",
      " [5.44593930e-02]\n",
      " [2.90122628e-03]\n",
      " [4.19535905e-01]\n",
      " [1.39808357e-02]\n",
      " [1.71142817e-03]\n",
      " [2.85142660e-03]\n",
      " [2.84639299e-02]\n",
      " [1.77704692e-02]\n",
      " [1.52805150e-02]\n",
      " [1.13007426e-03]\n",
      " [1.21087432e-02]\n",
      " [3.07095051e-03]\n",
      " [1.22457743e-03]\n",
      " [1.00296736e-03]\n",
      " [3.44216824e-05]\n",
      " [3.42726707e-06]\n",
      " [8.24630260e-04]\n",
      " [8.24242830e-04]\n",
      " [2.22563744e-04]\n",
      " [1.23172998e-04]\n",
      " [2.16776133e-03]\n",
      " [7.34359026e-04]\n",
      " [1.35114789e-03]\n",
      " [1.83648467e-02]\n",
      " [1.03607178e-02]\n",
      " [4.64071333e-02]\n",
      " [5.41005433e-02]\n",
      " [7.05212355e-04]\n",
      " [8.90731812e-04]\n",
      " [2.96971202e-03]\n",
      " [9.88438606e-01]\n",
      " [9.42289829e-04]\n",
      " [2.40027905e-04]\n",
      " [1.10930204e-03]\n",
      " [4.97248769e-03]\n",
      " [1.36703253e-03]\n",
      " [4.29153442e-05]\n",
      " [9.13065255e-01]\n",
      " [1.22487545e-05]\n",
      " [1.21951103e-04]\n",
      " [2.15053558e-04]\n",
      " [1.01010054e-01]\n",
      " [1.36862129e-01]\n",
      " [9.54774022e-03]\n",
      " [7.87609816e-03]\n",
      " [6.14399314e-01]\n",
      " [3.90052795e-04]\n",
      " [4.02659178e-03]\n",
      " [9.46106434e-01]\n",
      " [1.35803223e-03]\n",
      " [7.43359327e-04]\n",
      " [2.33441591e-04]\n",
      " [1.82069838e-02]\n",
      " [1.44429505e-02]\n",
      " [1.68996155e-02]\n",
      " [7.11402297e-03]\n",
      " [2.24328041e-03]\n",
      " [2.24105716e-02]]\n"
     ]
    }
   ],
   "source": [
    "# digits \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "# size = 1000\n",
    "# X_moons, y_moons = make_moons(size, noise=0.05, random_state=42)\n",
    "\n",
    "# samples,features = X_moons.shape\n",
    "# print(samples,features)\n",
    "# X_moons_plus_bias = np.c_[np.ones((samples,1)),X_moons]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaled_X_moons = scaler.fit_transform(X_moons)\n",
    "# scaled_X_moons_bias = np.c_[np.ones((samples,1)),scaled_X_moons]\n",
    "\n",
    "digits = load_digits()\n",
    "samples,features = digits.data.shape\n",
    "#print(samples,features)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_digits = scaler.fit_transform(digits.data)\n",
    "scaled_digits_bias = np.c_[np.ones((samples,1)),scaled_digits]\n",
    "\n",
    "\n",
    "target = digits.target\n",
    "target[target != 5]  = 0\n",
    "target[target == 5]  = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_digits_bias, target, test_size=0.2, shuffle=False)\n",
    "print('y_test',y_test)\n",
    "x_train_samples = X_train.shape[0]\n",
    "print(x_train_samples)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(x_train_samples / batch_size))\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None, features + 1),name='X')\n",
    "y = tf.placeholder(tf.float32,shape=(None, 1),name='y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([features + 1,1],-1,1,seed=42),name='theta')\n",
    "b = tf.Variable(tf.zeros([1])) \n",
    "print(X.shape,theta.shape)\n",
    "t = tf.add(tf.matmul(X, theta), b) \n",
    "Y_hat = tf.nn.sigmoid(t) \n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = Y_hat, labels = y) \n",
    "\n",
    "gradients_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "traning_op = gradients_optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    indices = np.random.randint(x_train_samples,size=batch_size)\n",
    "    x_batch = X_train[indices]\n",
    "    y_batch = y_train.reshape(-1,1)[indices]\n",
    "    return x_batch,y_batch\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "#         print ('epoch',epoch,'loss = ',\n",
    "#                loss.eval(feed_dict={X: scaled_X_moons_bias,\n",
    "#                                    y: y_moons.reshape(-1,1)}))\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_index,batch_size)\n",
    "            sess.run(traning_op,feed_dict={X: X_batch,y: y_batch})\n",
    "        \n",
    "       \n",
    "    best_theta = theta.eval()\n",
    "    y_pred_test = sess.run(Y_hat,feed_dict={X: X_test,y: y_test.reshape(-1,1)})\n",
    "    \n",
    "#print('best_theta')\n",
    "print(best_theta.shape)\n",
    "print(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5c94476e0479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_score(y_test,y_pred_test)\n",
    "\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Build Example Data is CSV format, but use <whatever> data\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "def buildDataFromSet():\n",
    "    digits = datasets.load_digits()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.72, random_state=42)\n",
    "    f=open('cs-training.csv','w')\n",
    "    for i,j in enumerate(X_train):\n",
    "        k=np.append(np.array(y_train[i]),j   )\n",
    "        f.write(\",\".join([str(s) for s in k]) + '\\n')\n",
    "    f.close()\n",
    "    f=open('cs-testing.csv','w')\n",
    "    for i,j in enumerate(X_test):\n",
    "        k=np.append(np.array(y_test[i]),j   )\n",
    "        f.write(\",\".join([str(s) for s in k]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "\n",
    "# Convert to one hot\n",
    "def convertOneHot(data):\n",
    "    y=np.array([int(i[0]) for i in data])\n",
    "    y_onehot=[0]*len(y)\n",
    "    for i,j in enumerate(y):\n",
    "        y_onehot[i]=[0]*(y.max() + 1)\n",
    "        y_onehot[i][j]=1\n",
    "    return (y,y_onehot)\n",
    "\n",
    "\n",
    "buildDataFromSet()\n",
    "\n",
    "\n",
    "data = genfromtxt('cs-training.csv',delimiter=',')  # Training data\n",
    "test_data = genfromtxt('cs-testing.csv',delimiter=',')  # Test data\n",
    "\n",
    "x_train=np.array([ i[1::] for i in data])\n",
    "y_train,y_train_onehot = convertOneHot(data)\n",
    "\n",
    "x_test=np.array([ i[1::] for i in test_data])\n",
    "y_test,y_test_onehot = convertOneHot(test_data)\n",
    "\n",
    "\n",
    "#  A number of features\n",
    "#  B = number of digits\n",
    "A=data.shape[1]-1 # Number of features, Note first is y\n",
    "B=len(y_train_onehot[0])\n",
    "tf_in = tf.placeholder(\"float\", [None, A]) # Features\n",
    "tf_weight = tf.Variable(tf.zeros([A,B]))\n",
    "tf_bias = tf.Variable(tf.zeros([B]))\n",
    "tf_softmax = tf.nn.softmax(tf.matmul(tf_in,tf_weight) + tf_bias)\n",
    "\n",
    "# Training via backpropagation\n",
    "tf_softmax_correct = tf.placeholder(\"float\", [None,B])\n",
    "tf_cross_entropy = -tf.reduce_sum(tf_softmax_correct*tf.log(tf_softmax))\n",
    "\n",
    "# Train using tf.train.GradientDescentOptimizer\n",
    "tf_train_step = tf.train.GradientDescentOptimizer(0.01).minimize(tf_cross_entropy)\n",
    "\n",
    "# Add accuracy checking nodes\n",
    "tf_correct_prediction = tf.equal(tf.argmax(tf_softmax,1), tf.argmax(tf_softmax_correct,1))\n",
    "tf_accuracy = tf.reduce_mean(tf.cast(tf_correct_prediction, \"float\"))\n",
    "\n",
    "# Initialize and run\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"...\")\n",
    "# Run the training\n",
    "\n",
    "k=[]\n",
    "for i in range(100):\n",
    "    sess.run(tf_train_step, feed_dict={tf_in: x_train, tf_softmax_correct: y_train_onehot})\n",
    "\n",
    "# Print accuracy\n",
    "    result = sess.run(tf_accuracy, feed_dict={tf_in: x_test, tf_softmax_correct: y_test_onehot})\n",
    "    print \"Run {},{}\".format(i,result)\n",
    "    k.append(result)\n",
    "k=np.array(k)\n",
    "print(np.where(k==k.max()))\n",
    "print \"Max: {}\".format(k.max())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Display the first digit\n",
    "plt.figure(1, figsize=(2, 2))\n",
    "plt.imshow(digits.images[1], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
