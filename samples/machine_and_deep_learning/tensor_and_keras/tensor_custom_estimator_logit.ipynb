{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features,labels,batch_size):\n",
    "    display('train_input_fn features ',type(features))\n",
    "    display('train_input_fn labels',type(labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
    "    return dataset.shuffle(1000,seed=42).repeat().batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features,labels,batch_size):\n",
    "    features = dict(features)\n",
    "    if labels is None:\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features,labels)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0            6.4         2.8          5.6         2.2\n",
      "1            5.0         2.3          3.3         1.0\n",
      "2            4.9         2.5          4.5         1.7\n",
      "3            4.9         3.1          1.5         0.1\n",
      "4            5.7         3.8          1.7         0.3\n",
      "..           ...         ...          ...         ...\n",
      "115          5.5         2.6          4.4         1.2\n",
      "116          5.7         3.0          4.2         1.2\n",
      "117          4.4         2.9          1.4         0.2\n",
      "118          4.8         3.0          1.4         0.1\n",
      "119          5.5         2.4          3.7         1.0\n",
      "\n",
      "[120 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# create input function\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "CSV_COLUMN_NAMES = ['SepalLength','SepalWidth',\n",
    "                   'PetalLength','PetalWidth','Species']\n",
    "SPECIES = ['Setosa','Versocolor','Virginica']\n",
    "\n",
    "def load_data():\n",
    "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1],TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1],TEST_URL)\n",
    "    \n",
    "    train = pd.read_csv(train_path,names=CSV_COLUMN_NAMES,header=0)\n",
    "    X_train, y_train = train,train.pop('Species')\n",
    "    \n",
    "    test = pd.read_csv(test_path,names=CSV_COLUMN_NAMES,header=0)\n",
    "    X_test, y_test = test,test.pop('Species')\n",
    "    \n",
    "    return (X_train,y_train), (X_test,y_test)\n",
    "\n",
    "(X_train,y_train), (X_test,y_test) = load_data()\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(features,labels,mode,params):\n",
    "        \"\"\"DNN with 2 hidden layers , and dropout of 0.1 probability\"\"\"\n",
    "        input_layer = tf.feature_column.input_layer(features,\n",
    "                                                   params['feature_columns'])\n",
    "\n",
    "        hidden1 = tf.layers.dense(input_layer,units=params['n_hidden1'],\n",
    "                                 activation=tf.nn.relu)\n",
    "        dropout1 = tf.layers.dropout(inputs=hidden1,rate=0.1, \n",
    "                                     training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        hidden2 = tf.layers.dense(dropout1,units=params['n_hidden2'],\n",
    "                                 activation=tf.nn.relu)\n",
    "        dropout2 = tf.layers.dropout(inputs=hidden2,rate=0.1, \n",
    "                                     training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        \n",
    "        #compute logits (one per class)\n",
    "        logits = tf.layers.dense(dropout2,params['n_classes'])\n",
    "        \n",
    "        #compute predictions\n",
    "        predicted_classes = tf.argmax(logits,axis=1)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions = {\n",
    "                'class_ids' : predicted_classes,\n",
    "                'probabilities': tf.nn.softmax(logits),\n",
    "                'logits':logits\n",
    "            }\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode,predictions=predictions)\n",
    "    \n",
    "        \n",
    "        #compute loss\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,\n",
    "                                                      logits=logits)\n",
    "        \n",
    "        #compute evaluation metrics\n",
    "        accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                      predictions = predicted_classes,\n",
    "                                      name='acc_op')\n",
    "        \n",
    "        metrics = {'accuracy':accuracy}\n",
    "        tf.summary.scalar('accuracy',accuracy[1])\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode,loss = loss,\n",
    "                                             eval_metric_ops=metrics)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(loss,\n",
    "                                     global_step = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'my_model', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020B67785848>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.RunConfig(tf_random_seed=42)\n",
    "\n",
    "feature_columns = []\n",
    "for key in X_train.columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "display(feature_columns)\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns':feature_columns,\n",
    "        'n_hidden1': 10,\n",
    "        'n_hidden2': 10,\n",
    "        'n_classes': 3\n",
    "    },\n",
    "    model_dir = 'my_model',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_input_fn features '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'train_input_fn labels'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from my_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into my_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.21818577, step = 5500\n",
      "INFO:tensorflow:global_step/sec: 493.977\n",
      "INFO:tensorflow:loss = 0.22843137, step = 5600 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1033.69\n",
      "INFO:tensorflow:loss = 0.15421426, step = 5700 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.13\n",
      "INFO:tensorflow:loss = 0.2791499, step = 5800 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1066.67\n",
      "INFO:tensorflow:loss = 0.390869, step = 5900 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.321\n",
      "INFO:tensorflow:loss = 0.302419, step = 6000 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 954.935\n",
      "INFO:tensorflow:loss = 0.229864, step = 6100 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1033.68\n",
      "INFO:tensorflow:loss = 0.28034362, step = 6200 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1055.45\n",
      "INFO:tensorflow:loss = 0.25727648, step = 6300 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.14\n",
      "INFO:tensorflow:loss = 0.23785774, step = 6400 (0.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into my_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.29708233.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x20b676f3f08>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_step = 1000\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(X_train,y_train,batch_size),\n",
    "    steps=train_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-09T11:13:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from my_model\\model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-09-11:13:04\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.96666664, global_step = 3000, loss = 0.14257695\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: my_model\\model.ckpt-3000\n",
      "eval_result {'accuracy': 0.96666664, 'loss': 0.14257695, 'global_step': 3000}\n",
      "eval_result 0.96666664\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(X_test,y_test,batch_size))\n",
    "\n",
    "print('eval_result',eval_result)\n",
    "print('eval_result',eval_result['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from my_model\\model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (100.0%), expected \"Setosa\"\n",
      "Prediction is \"Versocolor\" (95.1%), expected \"Versocolor\"\n",
      "Prediction is \"Virginica\" (99.8%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "#generate predictions from the model\n",
    "X_pred = {'SepalLength': [5.1,5.9,6.9],\n",
    "          'SepalWidth': [3.3,3.0,3.1],\n",
    "          'PetalLength': [1.7,4.2,5.4],\n",
    "          'PetalWidth': [0.5,1.5,2.1]}\n",
    "\n",
    "expected = ['Setosa','Versocolor','Virginica']\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(X_pred,\n",
    "                                 labels = None,\n",
    "                                 batch_size = batch_size))\n",
    "\n",
    "template = ( 'Prediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "            \n",
    "for pred_dict,label in zip(predictions,expected):\n",
    "    class_id = pred_dict['class_ids']\n",
    "    prob = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print(template.format(SPECIES[class_id],\n",
    "                         100 * prob , label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
