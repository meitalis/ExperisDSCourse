{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex p. 298\n",
    "#Info(D) = I(9,5)\n",
    "ID = -9/14 * np.log2(9/14) - 5/14*np.log2(5/14)\n",
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_Age = (((- (2/5) * np.log2(2/5)) - ( (3/5) * np.log2(3/5))) * (5/14)) + 0 + (((- (2/5) * np.log2(2/5)) - ( (3/5) * np.log2(3/5))) * (5/14))\n",
    "ID_Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high - 4 \n",
    "#medium - 6\n",
    "#low - 4\n",
    "\n",
    "#4/14 * I(2,2) + 6/14 * I(4,2) + 4/14 I(3,1)\n",
    "high = (((- (2/4) * np.log2(2/4)) - ( (2/4) * np.log2(2/4))) * (4/14))\n",
    "medium = (((- (4/6) * np.log2(4/6)) - ( (2/6) * np.log2(2/6))) * (6/14))\n",
    "low = (((- (3/4) * np.log2(3/4)) - ( (1/4) * np.log2(1/4))) * (4/14))\n",
    "\n",
    "ID_income = high + medium + low\n",
    "display(ID_income)\n",
    "\n",
    "Gain_income = ID - ID_income\n",
    "Gain_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no - 7\n",
    "#yes- 7\n",
    "\n",
    "# no                   yes\n",
    "#7/14 * I(3,4) + 7/14 * I(6,1) \n",
    "no = (((- (3/7) * np.log2(3/7)) - ( (4/7) * np.log2(4/7))) * (7/14))\n",
    "yes = (((- (6/7) * np.log2(6/7)) - ( (1/7) * np.log2(1/7))) * (7/14))\n",
    "\n",
    "ID_student = no + yes\n",
    "ID_student\n",
    "\n",
    "Gain_student = ID - ID_student\n",
    "Gain_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fair - 8\n",
    "#exce- 6\n",
    "\n",
    "\n",
    "#8/14 * I(6,2) + 6/14 * I(3,3) \n",
    "fair = (((- (6/8) * np.log2(6/8)) - ( (2/8) * np.log2(2/8))) * (8/14))\n",
    "exce = (((- (3/6) * np.log2(3/6)) - ( (3/6) * np.log2(3/6))) * (6/14))\n",
    "\n",
    "ID_credit = fair + exce\n",
    "ID_credit\n",
    "\n",
    "Gain_credit = ID - ID_credit\n",
    "Gain_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex p. 299\n",
    "# + - 3,3\n",
    "\n",
    "Entropy = (((- (3/6) * np.log2(3/6)) - ( (3/6) * np.log2(3/6))))\n",
    "Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2 gain\n",
    "#T- 4\n",
    "#F- 2\n",
    "\n",
    "\n",
    "#4/6 * I(2,2) + 2/6 * I(1,1) \n",
    "T = 4/6 * 1\n",
    "F = 2/6 * 1\n",
    "\n",
    "ID_a2 = T + F\n",
    "display(ID_a2)\n",
    "\n",
    "Gain_a2 = Entropy - ID_a2\n",
    "Gain_a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature humidity uniques ['h' 'n'] counts [7 7]\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "2     h\n",
      "3     h\n",
      "4     n\n",
      "5     n\n",
      "6     n\n",
      "7     h\n",
      "8     n\n",
      "9     n\n",
      "10    n\n",
      "11    h\n",
      "12    n\n",
      "13    h\n",
      "Name: humidity, dtype: object\n",
      " y[idx_values] 0      no\n",
      "1      no\n",
      "2     yes\n",
      "3     yes\n",
      "7      no\n",
      "11    yes\n",
      "13     no\n",
      "Name: play, dtype: object\n",
      "value h idx_values [0, 1, 2, 3, 7, 11, 13] yes_count 3 no_count 4\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "2     h\n",
      "3     h\n",
      "4     n\n",
      "5     n\n",
      "6     n\n",
      "7     h\n",
      "8     n\n",
      "9     n\n",
      "10    n\n",
      "11    h\n",
      "12    n\n",
      "13    h\n",
      "Name: humidity, dtype: object\n",
      " y[idx_values] 4     yes\n",
      "5      no\n",
      "6     yes\n",
      "8     yes\n",
      "9     yes\n",
      "10    yes\n",
      "12    yes\n",
      "Name: play, dtype: object\n",
      "value n idx_values [4, 5, 6, 8, 9, 10, 12] yes_count 6 no_count 1\n",
      "feature outlook uniques ['o' 'r' 's'] counts [4 5 5]\n",
      "X[feature] 0     s\n",
      "1     s\n",
      "2     o\n",
      "3     r\n",
      "4     r\n",
      "5     r\n",
      "6     o\n",
      "7     s\n",
      "8     s\n",
      "9     r\n",
      "10    s\n",
      "11    o\n",
      "12    o\n",
      "13    r\n",
      "Name: outlook, dtype: object\n",
      " y[idx_values] 2     yes\n",
      "6     yes\n",
      "11    yes\n",
      "12    yes\n",
      "Name: play, dtype: object\n",
      "value o idx_values [2, 6, 11, 12] yes_count 4 no_count 0\n",
      "X[feature] 0     s\n",
      "1     s\n",
      "2     o\n",
      "3     r\n",
      "4     r\n",
      "5     r\n",
      "6     o\n",
      "7     s\n",
      "8     s\n",
      "9     r\n",
      "10    s\n",
      "11    o\n",
      "12    o\n",
      "13    r\n",
      "Name: outlook, dtype: object\n",
      " y[idx_values] 3     yes\n",
      "4     yes\n",
      "5      no\n",
      "9     yes\n",
      "13     no\n",
      "Name: play, dtype: object\n",
      "value r idx_values [3, 4, 5, 9, 13] yes_count 3 no_count 2\n",
      "X[feature] 0     s\n",
      "1     s\n",
      "2     o\n",
      "3     r\n",
      "4     r\n",
      "5     r\n",
      "6     o\n",
      "7     s\n",
      "8     s\n",
      "9     r\n",
      "10    s\n",
      "11    o\n",
      "12    o\n",
      "13    r\n",
      "Name: outlook, dtype: object\n",
      " y[idx_values] 0      no\n",
      "1      no\n",
      "7      no\n",
      "8     yes\n",
      "10    yes\n",
      "Name: play, dtype: object\n",
      "value s idx_values [0, 1, 7, 8, 10] yes_count 2 no_count 3\n",
      "feature temp uniques ['c' 'h' 'm'] counts [4 4 6]\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "2     h\n",
      "3     m\n",
      "4     c\n",
      "5     c\n",
      "6     c\n",
      "7     m\n",
      "8     c\n",
      "9     m\n",
      "10    m\n",
      "11    m\n",
      "12    h\n",
      "13    m\n",
      "Name: temp, dtype: object\n",
      " y[idx_values] 4    yes\n",
      "5     no\n",
      "6    yes\n",
      "8    yes\n",
      "Name: play, dtype: object\n",
      "value c idx_values [4, 5, 6, 8] yes_count 3 no_count 1\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "2     h\n",
      "3     m\n",
      "4     c\n",
      "5     c\n",
      "6     c\n",
      "7     m\n",
      "8     c\n",
      "9     m\n",
      "10    m\n",
      "11    m\n",
      "12    h\n",
      "13    m\n",
      "Name: temp, dtype: object\n",
      " y[idx_values] 0      no\n",
      "1      no\n",
      "2     yes\n",
      "12    yes\n",
      "Name: play, dtype: object\n",
      "value h idx_values [0, 1, 2, 12] yes_count 2 no_count 2\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "2     h\n",
      "3     m\n",
      "4     c\n",
      "5     c\n",
      "6     c\n",
      "7     m\n",
      "8     c\n",
      "9     m\n",
      "10    m\n",
      "11    m\n",
      "12    h\n",
      "13    m\n",
      "Name: temp, dtype: object\n",
      " y[idx_values] 3     yes\n",
      "7      no\n",
      "9     yes\n",
      "10    yes\n",
      "11    yes\n",
      "13     no\n",
      "Name: play, dtype: object\n",
      "value m idx_values [3, 7, 9, 10, 11, 13] yes_count 4 no_count 2\n",
      "feature wind uniques ['s' 'w'] counts [6 8]\n",
      "X[feature] 0     w\n",
      "1     s\n",
      "2     w\n",
      "3     w\n",
      "4     w\n",
      "5     s\n",
      "6     s\n",
      "7     w\n",
      "8     w\n",
      "9     w\n",
      "10    s\n",
      "11    s\n",
      "12    w\n",
      "13    s\n",
      "Name: wind, dtype: object\n",
      " y[idx_values] 1      no\n",
      "5      no\n",
      "6     yes\n",
      "10    yes\n",
      "11    yes\n",
      "13     no\n",
      "Name: play, dtype: object\n",
      "value s idx_values [1, 5, 6, 10, 11, 13] yes_count 3 no_count 3\n",
      "X[feature] 0     w\n",
      "1     s\n",
      "2     w\n",
      "3     w\n",
      "4     w\n",
      "5     s\n",
      "6     s\n",
      "7     w\n",
      "8     w\n",
      "9     w\n",
      "10    s\n",
      "11    s\n",
      "12    w\n",
      "13    s\n",
      "Name: wind, dtype: object\n",
      " y[idx_values] 0      no\n",
      "2     yes\n",
      "3     yes\n",
      "4     yes\n",
      "7      no\n",
      "8     yes\n",
      "9     yes\n",
      "12    yes\n",
      "Name: play, dtype: object\n",
      "value w idx_values [0, 2, 3, 4, 7, 8, 9, 12] yes_count 6 no_count 2\n",
      "feature_max outlook entropies find min [0.7884504573082896, 0.6935361388961918, 0.9110633930116763, 0.8921589282623617]\n",
      "************* outlook - sunny\n",
      "feature humidity uniques ['h' 'n'] counts [3 2]\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "7     h\n",
      "8     n\n",
      "10    n\n",
      "Name: humidity, dtype: object\n",
      " y[idx_values] 0    no\n",
      "1    no\n",
      "7    no\n",
      "Name: play, dtype: object\n",
      "value h idx_values [0, 1, 7] yes_count 0 no_count 3\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "7     h\n",
      "8     n\n",
      "10    n\n",
      "Name: humidity, dtype: object\n",
      " y[idx_values] 8     yes\n",
      "10    yes\n",
      "Name: play, dtype: object\n",
      "value n idx_values [8, 10] yes_count 2 no_count 0\n",
      "feature temp uniques ['c' 'h' 'm'] counts [1 2 2]\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "7     m\n",
      "8     c\n",
      "10    m\n",
      "Name: temp, dtype: object\n",
      " y[idx_values] 8    yes\n",
      "Name: play, dtype: object\n",
      "value c idx_values [8] yes_count 1 no_count 0\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "7     m\n",
      "8     c\n",
      "10    m\n",
      "Name: temp, dtype: object\n",
      " y[idx_values] 0    no\n",
      "1    no\n",
      "Name: play, dtype: object\n",
      "value h idx_values [0, 1] yes_count 0 no_count 2\n",
      "X[feature] 0     h\n",
      "1     h\n",
      "7     m\n",
      "8     c\n",
      "10    m\n",
      "Name: temp, dtype: object\n",
      " y[idx_values] 7      no\n",
      "10    yes\n",
      "Name: play, dtype: object\n",
      "value m idx_values [7, 10] yes_count 1 no_count 1\n",
      "feature wind uniques ['s' 'w'] counts [2 3]\n",
      "X[feature] 0     w\n",
      "1     s\n",
      "7     w\n",
      "8     w\n",
      "10    s\n",
      "Name: wind, dtype: object\n",
      " y[idx_values] 1      no\n",
      "10    yes\n",
      "Name: play, dtype: object\n",
      "value s idx_values [1, 10] yes_count 1 no_count 1\n",
      "X[feature] 0     w\n",
      "1     s\n",
      "7     w\n",
      "8     w\n",
      "10    s\n",
      "Name: wind, dtype: object\n",
      " y[idx_values] 0     no\n",
      "7     no\n",
      "8    yes\n",
      "Name: play, dtype: object\n",
      "value w idx_values [0, 7, 8] yes_count 1 no_count 2\n",
      "feature_max humidity entropies find min [0, 0.4, 0.9509775004326937]\n"
     ]
    }
   ],
   "source": [
    "#Ex 300\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def gain_func(entropy_root,X,y):\n",
    "    #print('entropy_root',entropy_root,'X',X,'y',y,sep='\\n')\n",
    "    \n",
    "    if (len(X.columns) == 0):\n",
    "        return\n",
    "    \n",
    "    if entropy_root == None:\n",
    "        #handle root\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        #print('unique', unique, 'counts',counts)\n",
    "                        \n",
    "        len_arr = y.shape[0]\n",
    "        count = 0\n",
    "        entropy_root = np.float(0)\n",
    "    \n",
    "        for i in counts:\n",
    "            count += i\n",
    "            entropy_root += (- (i/len_arr) * np.log2(i/len_arr))\n",
    "            \n",
    "        entropy_root = entropy_root * (count/len_arr)\n",
    "        gain = 0\n",
    "        \n",
    "        #print(y.name,'entropy_root',entropy_root,'gain',gain)\n",
    "              \n",
    "        \n",
    "        gain_func(entropy_root,X,y) #(y.name,feature_entropy,gain)\n",
    "        \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        gains = []\n",
    "        entropies = []\n",
    "        for feature in X.columns:\n",
    "            uniques, indexes,counts = np.unique(X[feature], return_counts=True,return_index=True)\n",
    "            print('feature',feature,'uniques', uniques,'counts',counts)\n",
    "            feature_entropy = 0\n",
    "            \n",
    "            for value in uniques:\n",
    "                idx_values = X[feature].index[X[feature] == value].tolist()\n",
    "                print('X[feature]',X[feature])\n",
    "                print(' y[idx_values]', y[idx_values])\n",
    "                yes_count = sum(map(lambda x : x == 'yes', y[idx_values]))\n",
    "                no_count = sum(map(lambda x : x == 'no', y[idx_values]))\n",
    "                print('value',value,'idx_values',idx_values,'yes_count',yes_count,'no_count',no_count)\n",
    "                \n",
    "                targets_by_feature_count = yes_count + no_count\n",
    "                feature_count = X[feature].size\n",
    "                \n",
    "                if (no_count != 0 and yes_count != 0):\n",
    "                    feature_entropy += (((- (yes_count/targets_by_feature_count) * np.log2(yes_count/targets_by_feature_count)) -\n",
    "                                    ( (no_count/targets_by_feature_count) * np.log2(no_count/targets_by_feature_count))) * \n",
    "                                   (targets_by_feature_count/feature_count))\n",
    "                \n",
    "                \n",
    "               \n",
    "            \n",
    "            gain = entropy_root - feature_entropy\n",
    "            gains.append(gain)\n",
    "            entropies.append(feature_entropy)\n",
    "            #print('feature',feature,'value',value,'entropy',feature_entropy,'gain',gain,end='\\n\\n')\n",
    "            #yield (feature,feature_entropy,gain)\n",
    "            \n",
    "        feature_max = X.columns[np.argmax(gains)] \n",
    "        print('feature_max',feature_max,'entropies find min',entropies)\n",
    "        #uniques, indexes,counts = np.unique(X[feature_max], return_counts=True,return_index=True)\n",
    "        #X_part = X.drop(feature_max,axis=1)\n",
    "        #for value in uniques:\n",
    "        #    print('value',value)\n",
    "        #    idx_values = X[feature_max].index[X[feature_max] == value].tolist()\n",
    "        #    gain_func(np.min(entropies),X_part[X_part.index.isin(idx_values)],y[y.index.isin(idx_values)])\n",
    "\n",
    "    \n",
    "d = {'outlook':['s','s','o','r','r','r','o','s','s','r','s','o','o','r'],\n",
    "    'temp':['h','h','h','m','c','c','c','m','c','m','m','m','h','m'],\n",
    "    'humidity':['h','h','h','h','n','n','n','h','n','n','n','h','n','h'],\n",
    "    'wind':['w','s','w','w','w','s','s','w','w','w','s','s','w','s'],\n",
    "    'play':['no','no','yes','yes','yes','no','yes','no','yes','yes','yes','yes','yes','no']}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "X = df.drop('play',axis=1)\n",
    "y = df.play\n",
    "\n",
    "gain_func(None,X,y)\n",
    "print('************* outlook - sunny')\n",
    "X_part = X.drop('outlook',axis=1)\n",
    "gain_func(0.6935361,X_part[X_part.index.isin([0, 1, 7, 8, 10])] ,y[y.index.isin([0, 1, 7, 8, 10])])\n",
    "#for g in gain_func(None,X,y):\n",
    " #   print('********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Play No 5\n",
    "#Play Yes 9\n",
    "\n",
    "Entropy = (((- (5/14) * np.log2(5/14)) - ( (9/14) * np.log2(9/14))))\n",
    "Entropy\n",
    "\n",
    "#Outlook\n",
    "#Sunny - 5\n",
    "#Overcast - 4\n",
    "#Rain - 5\n",
    "\n",
    "#5/14 * I(2,3) + 4/14 * I(4,0) + 5/14 I(3,2)\n",
    "Sunny = (((- (2/5) * np.log2(2/5)) - ( (3/5) * np.log2(3/5))) * (5/14))\n",
    "Overcast = 0\n",
    "Rain = (((- (3/5) * np.log2(3/5)) - ( (2/5) * np.log2(2/5))) * (5/14))\n",
    "print('Rain',Rain)\n",
    "Outlook = Sunny + Overcast + Rain\n",
    "display(Outlook)\n",
    "\n",
    "Gain = Entropy - Outlook\n",
    "Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outlook\n",
    "#Sunny - 5\n",
    "\n",
    "# temp \n",
    "#   hot = 2 (0,2)\n",
    "#   mild - 2 (1,1)\n",
    "#   cool - 1 (1,0)\n",
    "\n",
    "Sunny_Temp = (((- (1/2) * np.log2(1/2)) - ( (1/2) * np.log2(1/2))) * (2/5))\n",
    "Sunny_Temp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \"Generic tree node.\"\n",
    "    def __init__(self, name='root', children=None):\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        if children is not None:\n",
    "            for child in children:\n",
    "                self.add_child(child)\n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    def add_child(self, node):\n",
    "        assert isinstance(node, Tree)\n",
    "        self.children.append(node)\n",
    "#    *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-422a4f148f14>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-422a4f148f14>\"\u001b[1;36m, line \u001b[1;32m46\u001b[0m\n\u001b[1;33m    Introduction\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from pprint import pprint  \n",
    "#Import the dataset and define the feature as well as the target datasets / columns#  \n",
    "dataset = pd.read_csv('zoo.csv',  \n",
    "                      names=['animal_name','hair','feathers','eggs','milk',  \n",
    "                                                   'airbone','aquatic','predator','toothed','backbone',  \n",
    "                                                  'breathes','venomous','fins','legs','tail','domestic','catsize','class',])#Import all columns omitting the fist which consists the names of the animals  \n",
    "#We drop the animal names since this is not a good feature to split the data on  \n",
    "dataset=dataset.drop('animal_name',axis=1)  \n",
    "  \n",
    "def entropy(target_col):  \n",
    "    \n",
    "    elements,counts = np.unique(target_col,return_counts = True)  \n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])  \n",
    "    return entropy  \n",
    "  \n",
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):  \n",
    "         \n",
    "    #Calculate the entropy of the total dataset  \n",
    "    total_entropy = entropy(data[target_name])  \n",
    "      \n",
    "    ##Calculate the entropy of the dataset  \n",
    "      \n",
    "    #Calculate the values and the corresponding counts for the split attribute   \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)  \n",
    "      \n",
    "    #Calculate the weighted entropy  \n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])  \n",
    "      \n",
    "    #Calculate the information gain  \n",
    "    Information_Gain = total_entropy - Weighted_Entropy  \n",
    "    return Information_Gain  \n",
    "  \n",
    "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):  \n",
    "  \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#  \n",
    "      \n",
    "    #If all target_values have the same value, return this value  \n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:  \n",
    "        return np.unique(data[target_attribute_name])[0]  \n",
    "      \n",
    "    #If the dataset is empty, return the mode target feature value in the original dataset  \n",
    "    elif len(data)==0:  \n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(origin\n",
    "Introduction\n",
    "aldata[target_attribute_name],return_counts=True)[1])]  \n",
    "      \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that  \n",
    "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence  \n",
    "    #the mode target feature value is stored in the parent_node_class variable.  \n",
    "      \n",
    "    elif len(features) ==0:  \n",
    "        return parent_node_class  \n",
    "      \n",
    "    #If none of the above holds true, grow the tree!  \n",
    "      \n",
    "    else:  \n",
    "        #Set the default value for this node --> The mode target feature value of the current node  \n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]  \n",
    "          \n",
    "        #Select the feature which best splits the dataset  \n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset  \n",
    "        best_feature_index = np.argmax(item_values)  \n",
    "        best_feature = features[best_feature_index]  \n",
    "          \n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information  \n",
    "        #gain in the first run  \n",
    "        tree = {best_feature:{}}  \n",
    "          \n",
    "          \n",
    "        #Remove the feature with the best inforamtion gain from the feature space  \n",
    "        features = [i for i in features if i != best_feature]  \n",
    "          \n",
    "        #Grow a branch under the root node for each possible value of the root node feature  \n",
    "          \n",
    "        for value in np.unique(data[best_feature]):  \n",
    "            value = value  \n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets  \n",
    "            sub_data = data.where(data[best_feature] == value).dropna()  \n",
    "              \n",
    "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!  \n",
    "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)  \n",
    "              \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node  \n",
    "            tree[best_feature][value] = subtree  \n",
    "              \n",
    "        return(tree)      \n",
    "                  \n",
    "def predict(query,tree,default = 1):  \n",
    "    \n",
    "    for key in list(query.keys()):  \n",
    "        if key in list(tree.keys()):  \n",
    "            \n",
    "            try:  \n",
    "                result = tree[key][query[key]]   \n",
    "            except:  \n",
    "                return default  \n",
    "    \n",
    "            result = tree[key][query[key]]  \n",
    "            \n",
    "            if isinstance(result,dict):  \n",
    "                return predict(query,result)  \n",
    "            else:  \n",
    "                return result  \n",
    "  \n",
    "def train_test_split(dataset):  \n",
    "    training_data = dataset.iloc[:80].reset_index(drop=True)#We drop the index respectively relabel the index  \n",
    "    #starting form 0, because we do not want to run into errors regarding the row labels / indexes  \n",
    "    testing_data = dataset.iloc[80:].reset_index(drop=True)  \n",
    "    return training_data,testing_data  \n",
    "  \n",
    "training_data = train_test_split(dataset)[0]  \n",
    "testing_data = train_test_split(dataset)[1]   \n",
    "  \n",
    "def test(data,tree):  \n",
    "    #Create new query instances by simply removing the target feature column from the original dataset and   \n",
    "    #convert it to a dictionary  \n",
    "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")  \n",
    "      \n",
    "    #Create a empty DataFrame in whose columns the prediction of the tree are stored  \n",
    "    predicted = pd.DataFrame(columns=[\"predicted\"])   \n",
    "      \n",
    "    #Calculate the prediction accuracy  \n",
    "    for i in range(len(data)):  \n",
    "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0)   \n",
    "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[\"class\"])/len(data))*100,'%')  \n",
    "      \n",
    "tree = ID3(training_data,training_data,training_data.columns[:-1])  \n",
    "pprint(tree)  \n",
    "test(testing_data,tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth = 6, depth = 1):\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def fit(self, data, target):\n",
    "        if self.depth <= self.max_depth: print(f\"processing at Depth: {self.depth}\")\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.independent = self.data.columns.tolist()\n",
    "        self.independent.remove(target)\n",
    "        if self.depth <= self.max_depth:\n",
    "            self.__validate_data()\n",
    "            self.impurity_score = self.__calculate_impurity_score(self.data[self.target])\n",
    "            self.criteria, self.split_feature, self.information_gain = self.__find_best_split()\n",
    "            if self.criteria is not None and self.information_gain > 0: self.__create_branches()\n",
    "        else: \n",
    "            print(\"Stopping splitting as Max depth reached\")\n",
    "    \n",
    "    def __create_branches(self):\n",
    "        self.left = DecisionTree(max_depth = self.max_depth, \n",
    "                                 depth = self.depth + 1)\n",
    "        self.right = DecisionTree(max_depth = self.max_depth, \n",
    "                                 depth = self.depth + 1)\n",
    "        left_rows = self.data[self.data[self.split_feature] <= self.criteria] \n",
    "        right_rows = self.data[self.data[self.split_feature] > self.criteria] \n",
    "        self.left.fit(data = left_rows, target = self.target)\n",
    "        self.right.fit(data = right_rows, target = self.target)\n",
    "    \n",
    "    def __calculate_impurity_score(self, data):\n",
    "       if data is None or data.empty: return 0\n",
    "       p_i, _ = data.value_counts().apply(lambda x: x/len(data)).tolist() \n",
    "       return p_i * (1 - p_i) * 2\n",
    "    \n",
    "    def __find_best_split(self):\n",
    "        best_split = {}\n",
    "        for col in self.independent:\n",
    "            information_gain, split = self.__find_best_split_for_column(col)\n",
    "            if split is None: continue\n",
    "            if not best_split or best_split[\"information_gain\"] < information_gain:\n",
    "                best_split = {\"split\": split, \"col\": col, \"information_gain\": information_gain}\n",
    "\n",
    "        return best_split.get(\"split\"), best_split.get(\"col\"), best_split.get(\"information_gain\")\n",
    "\n",
    "    def __find_best_split_for_column(self, col):\n",
    "        x = self.data[col]\n",
    "        unique_values = x.unique()\n",
    "        if len(unique_values) == 1: return None, None\n",
    "        information_gain = None\n",
    "        split = None\n",
    "        for val in unique_values:\n",
    "            left = x <= val\n",
    "            right = x > val\n",
    "            left_data = self.data[left]\n",
    "            right_data = self.data[right]\n",
    "            left_impurity = self.__calculate_impurity_score(left_data[self.target])\n",
    "            right_impurity = self.__calculate_impurity_score(right_data[self.target])\n",
    "            score = self.__calculate_information_gain(left_count = len(left_data),\n",
    "                                                      left_impurity = left_impurity,\n",
    "                                                      right_count = len(right_data),\n",
    "                                                      right_impurity = right_impurity)\n",
    "            if information_gain is None or score > information_gain: \n",
    "                information_gain = score \n",
    "                split = val\n",
    "        return information_gain, split\n",
    "    \n",
    "    def __calculate_information_gain(self, left_count, left_impurity, right_count, right_impurity):\n",
    "        return self.impurity_score - ((left_count/len(self.data)) * left_impurity + \\\n",
    "                                      (right_count/len(self.data)) * right_impurity)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return np.array([self.__flow_data_thru_tree(row) for _, row in data.iterrows()])\n",
    "\n",
    "    def __validate_data(self):\n",
    "        non_numeric_columns = self.data[self.independent].select_dtypes(include=['category', 'object', 'bool']).columns.tolist()\n",
    "        if(len(set(self.independent).intersection(set(non_numeric_columns))) != 0):\n",
    "            raise RuntimeError(\"Not all columns are numeric\")\n",
    "        \n",
    "        self.data[self.target] = self.data[self.target].astype(\"category\")\n",
    "        if(len(self.data[self.target].cat.categories) != 2):\n",
    "            raise RuntimeError(\"Implementation is only for Binary Classification\")\n",
    "\n",
    "    def __flow_data_thru_tree(self, row):\n",
    "        if self.is_leaf_node: return self.probability\n",
    "        tree = self.left if row[self.split_feature] <= self.criteria else self.right\n",
    "        return tree.__flow_data_thru_tree(row)\n",
    "        \n",
    "    @property\n",
    "    def is_leaf_node(self): return self.left is None\n",
    "\n",
    "    @property\n",
    "    def probability(self): \n",
    "        return self.data[self.target].value_counts().apply(lambda x: x/len(self.data)).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
