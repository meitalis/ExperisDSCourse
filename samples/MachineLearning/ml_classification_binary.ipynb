{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 70000 images of size 28*28, each image has 784 features. \n",
    "each feature represents one pixel's intensity from 0 to 255 (should be white)\n",
    "\n",
    "The MNIST dataset is already split to train set (60000) and test set (10000)\n",
    "\n",
    "shuffle is important since some alg, are sensitive to the order of the train set and they perform poorly if they get many similar instances in a row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = 'mnist-original.mat'\n",
    "\n",
    "mnist = loadmat(mnist_path)\n",
    "X = mnist['data'].T\n",
    "y = mnist['label'][0]\n",
    "display(X.shape , y.shape)\n",
    "\n",
    "#peek a digit\n",
    "some_index = 36000\n",
    "some_digit = X[some_index]\n",
    "display(some_digit.shape)\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image,cmap='binary')\n",
    "plt.axis('off')\n",
    "\n",
    "#show y value\n",
    "display(y[36000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train & test \n",
    "train_size = 60000\n",
    "X_train,y_train = X[:train_size],y[:train_size]\n",
    "X_test,y_test = X[train_size:],y[train_size:]\n",
    "\n",
    "\n",
    "#shuffle\n",
    "shuffle_index = np.random.permutation(train_size)\n",
    "X_train,y_train = X[shuffle_index],y[shuffle_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Binary Classifier - By SGDClassifier\n",
    "# Stochastic Gradient Descent\n",
    "The class implements regularized linear classifier (SVM,logistic regression,etc) with SGD training\n",
    "the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing learning rate. \n",
    "\n",
    "The model it fits can be controlled with loss parameter\n",
    "by default, it fits a linear support vector machine (using the 'hinge' loss)\n",
    "log loss gives logistic regression\n",
    "perceptron is the linear loss used by the perceptron alg. \n",
    "\n",
    "The classifier has the advantage of being capable of handling very large dataset efficiently, and is also wekk suited for online learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "display(y_train)\n",
    "display(y_train_5, y_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=0,max_iter=50)\n",
    "sgd_clf.fit(X_train,y_train_5)\n",
    "\n",
    "#display(some_digit)\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measure - cross_val_score()\n",
    "evaluating a classifier is often significantly trickier than evaluating a regressor\n",
    "a good start is to use cross-validation\n",
    "\n",
    "the **cross_val_score()** return the ratio of correct predictions. \n",
    "\n",
    "~95% looks good but if we will write & check the Never5Classifier , we will get also 90% accuracy. \n",
    "This is because only about 10% of the images are 5s. so if you always guess than an image is not 5 , you will get right about 90% of the time\n",
    "\n",
    "This demonstrates why accuracy is generally not the preferred performance measure for classifier, especially when you are dealing with skewed datasets (סט נתונים מוטה)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf,X_train,y_train_5,cv=3,scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self,X,y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "        \n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf,X_train,y_train_5,cv=3,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measure - Confusion Matrix - cross_val_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a much better way to evaluate the performance of a classifier is to look at the confusion matrix\n",
    "The idea is to count the number of times instances of class A are classified as class B\n",
    "\n",
    "for example, to know the number of times the classifier confused images of 5s with 3s, you would look in the 5th row and the 3rd column of the confusion matrix\n",
    "To compute the confusion matrix, you first need to have a set of predictions\n",
    "\n",
    "You could make predictions on the test set, but let's keep it untouched for now\n",
    "you want to use yout test set only at the very end of your project, once you have a classifier you are ready to launch\n",
    "\n",
    "Instead of, you can use the **cross_val_predict() **\n",
    "\n",
    "Like the cross_val_score() the cross_val_predict() also performs K-cross validation, but instead of returning the evaluations scores, it returns for each element the prediction that was obtained for that element when it was in the test set\n",
    "only cross validation strategies that assign all elements to a test set exactly once can be used (otherise  an exception is raised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf,X_train,y_train_5,cv=3)\n",
    "\n",
    "conf_mat = confusion_matrix(y_train_5,y_train_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize confusion matrix\n",
    "sns.heatmap(conf_mat,square=True,annot=True,cmap='Blues',fmt='d',cbar=False)\n",
    "plt.xlabel('Predicted Value',fontsize=12)\n",
    "plt.ylabel('True Value',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy / precision / recall (sensitivity or true positive rate TPR) / F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TN FP\n",
    "# FN TP\n",
    "\n",
    "# accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "accuracy = (53177 + 4479) / (53177 + 1402 + 942 + 4479)\n",
    "display('accuracy',accuracy)\n",
    "\n",
    "# precision = (TP) / (TP + FP)\n",
    "# accuracy of the positive prediction\n",
    "precision = 4479 / (4479 + 1402)\n",
    "display('precision',precision)\n",
    "\n",
    "# recall = (TP) / (TP + FN)\n",
    "# ratio of positive instances that are correctly detected \n",
    "recall = 4479 / (4479 + 942)\n",
    "display('recall',recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_5,y_train_pred) , recall_score(y_train_5,y_train_pred)\n",
    "#0.76 - when it claims an image represent 5, it is correct only 76% (precision_score)\n",
    "#0.82 - only detect 82% of the 5s (recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 = 2 / ( (1/precision) + (1/recall)) = 2 * ( (precision * recall) / (precision + recall) ) =  2TP / ( 2TP + FN + FP)\n",
    "# מאחר שממוצע הרמוני של קבוצת מספרים נוטה לעבר המספר הקטן ביותר שבה, הוא נוטה למזער את ההשפעה של מספרים גדולים ולהגדיל את ההשפעה של מספרים קטנים.\n",
    "\n",
    "# The harmonic mean give much more weight to low values\n",
    "# Thus, a classifier will only get a high F1 score if both recall and precision are high\n",
    "\n",
    "f1_score(y_train_5,y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex F1\n",
    "d = {'expected':[1,1,0,1,0,0,1,0,0,0],\n",
    "    'predicted':[1,0,0,1,0,0,1,1,1,0]}\n",
    "\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2],\n",
       "       [1, 3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666665"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix by hand\n",
    "# TN - 4 ex 0 pre 0 (4) FP ex 0 pre 1 (2)  \n",
    "# FN - 2 ex 1 pre 0 (1) TP ex 1 pre 1 (3) \n",
    "y_expected =  df['expected']\n",
    "y_predicted = df['predicted']\n",
    "\n",
    "conf_mat_ex = confusion_matrix(y_expected,y_predicted)\n",
    "display(conf_mat_ex)\n",
    "\n",
    "display(precision_score(y_expected,y_predicted) , recall_score(y_expected,y_predicted))\n",
    "f1_score(y_expected,y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
