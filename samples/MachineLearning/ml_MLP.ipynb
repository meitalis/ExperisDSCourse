{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import  StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_train shape '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y_test shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_path = 'mnist-original.mat'\n",
    "\n",
    "mnist = loadmat(mnist_path)\n",
    "X = mnist['data'].T\n",
    "y = mnist['label'][0]\n",
    "#display(X.shape , y.shape)\n",
    "\n",
    "# Scale all X values\n",
    "scaler = StandardScaler()\n",
    "X_scaled  = scaler.fit_transform(X)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.0005,train_size=0.0005, random_state=0)\n",
    "train_index, test_index = next(sss.split(X=X_scaled, y=y))   \n",
    "\n",
    "X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "#display(y_train[:5])\n",
    "df_y_train = pd.get_dummies(y_train)\n",
    "y_train = df_y_train.values\n",
    "#display(y_train[:5])\n",
    "\n",
    "df_y_test = pd.get_dummies(y_test)\n",
    "y_test = df_y_test.values\n",
    "\n",
    "\n",
    "display('X_train shape ', X_train.shape,'X_test shape' , X_test.shape)\n",
    "display('Y_train shape ', y_train.shape,'Y_test shape' , y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPerceptron(BaseEstimator):\n",
    "    \n",
    "    #layers - includes input, #hidden, output\n",
    "    def __init__(self,layers_len,eta=0,random_state=50):\n",
    "        self.random_state = random_state\n",
    "        self.eta = eta\n",
    "        self.n_layers = len(layers_len)\n",
    "        self.layers_len = layers_len\n",
    "       \n",
    "        self.init_weights()\n",
    "     \n",
    "    \n",
    "    def init_weights(self):\n",
    "        rng = np.random.RandomState(self.random_state)       \n",
    "                \n",
    "        layers_len_next = self.layers_len.copy()\n",
    "        self.weights = []\n",
    "        layers_len_next.pop(0)\n",
    "        \n",
    "        print(self.layers_len)\n",
    "        \n",
    "        for layer_len, layer_len_next in zip(self.layers_len, layers_len_next):\n",
    "            #print(layer_len,layer_len_next)\n",
    "                        \n",
    "            w = rng.normal(loc=0.0,scale=0.1,size=[layer_len_next,layer_len + 1])\n",
    "            #print('w',w)\n",
    "            \n",
    "            self.weights.append(w)\n",
    "        \n",
    "        '''\n",
    "        for debug the sample page 376\n",
    "        '''\n",
    "#         self.weights.append(np.array([[0.5, 0, 0.3],\n",
    "#                                    [-0.2, 0.4, 0.7],\n",
    "#                                    [0,-0.5, -0.1]]))\n",
    "#         self.weights.append(np.array([[-0.5, 0.4, 0,0],\n",
    "#                                    [0.3, 0.6, 0.4,0]]))\n",
    "#         self.weights.append(np.array([[0.5, 0.7, 0]]))\n",
    "                            \n",
    "        \n",
    "        #print('weights', self.weights)\n",
    "        return self.weights\n",
    "    \n",
    "    def train(self,X,y,n_iter=50):\n",
    "    \n",
    "        n_samples = y.shape[0]\n",
    "        #print('n_iter',n_iter)\n",
    "        \n",
    "        for it in range(n_iter):\n",
    "            #print('train it',it)\n",
    "            self.back_propagation(X, y)\n",
    "           \n",
    "            \n",
    "    def back_propagation(self, X,y):\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        #print('x shape',n_samples)\n",
    "    \n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        #print('[back_propagation] layers_net \\n',layers_net,end='\\n\\n')\n",
    "        #print('[back_propagation] layers_input \\n',layers_input,end='\\n\\n')\n",
    "            \n",
    "        errors = [None] * self.n_layers\n",
    "        sigmas = [None] * self.n_layers\n",
    "        \n",
    "        \n",
    "        errors[-1] = (layers_input[-1][:-1] - y) * self.error_part(layers_input[-1][:-1])\n",
    "                \n",
    "        for layer_index in np.arange(self.n_layers - 2  ,0 , -1):\n",
    "            #print('[back_propagation] LAYER ',layer_index)\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_weights = np.delete(layer_weights, -1, axis=1) #remove weight for bias\n",
    "            #print('[back_propagation] layer_weights after remove bias \\n',layer_weights,end='\\n\\n')  \n",
    "            \n",
    "            sigmas[layer_index] = self.sigma(errors[layer_index+1],layer_weights)\n",
    "            #print('[back_propagation] sigmas \\n', sigmas[layer_index],end='\\n\\n') \n",
    "                       \n",
    "            layer_input = layers_input[layer_index]\n",
    "            layer_input = np.delete(layer_input, -1, axis=0)\n",
    "            #print('[back_propagation] layer_input after remove bias',layer_input,end='\\n\\n')\n",
    "            \n",
    "            errors[layer_index] =  sigmas[layer_index] * self.error_part(layer_input)\n",
    "            #print('[back_propagation] errors \\n',errors,end='\\n\\n') \n",
    "            \n",
    "            \n",
    "        #update weights\n",
    "        #print('[back_propagation] UPDATE WEIGHTS' ,end='\\n\\n') \n",
    "        tmp_weights = [None] * self.n_layers\n",
    "        for layer_index in np.arange(self.n_layers - 1):\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            layer_input = layers_input[layer_index]\n",
    "                                         \n",
    "            #print('[back_propagation] layer_weights',layer_weights ,end='\\n\\n') \n",
    "            #print('[back_propagation] layer_input',layer_input ,end='\\n\\n') \n",
    "        \n",
    "            #print('[back_propagation] errors[layer_index+1]',errors[layer_index+1],errors[layer_index+1].transpose().shape ,end='\\n\\n') \n",
    "            \n",
    "            tmp_weights =  errors[layer_index+1].transpose() @ layer_input.reshape(-1,1).transpose()\n",
    "            #print('[back_propagation] tmp_weights',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            tmp_weights =  tmp_weights * self.eta\n",
    "            #print('[back_propagation] tmp_weights * eta',tmp_weights ,end='\\n\\n') \n",
    "            \n",
    "            self.weights[layer_index]  = self.weights[layer_index] - tmp_weights\n",
    "            #print('[back_propagation]  comp weights',self.weights[layer_index] ,end='\\n\\n') \n",
    "        \n",
    "        \n",
    "        #print('[back_propagation]  self.weights',self.weights ,end='\\n\\n') \n",
    "       \n",
    "      \n",
    "        \n",
    "    def foward_propagation(self, X):\n",
    "        \n",
    "        #print('[foward_propagation] n_layers',self.n_layers)\n",
    "        \n",
    "        layers_input = [None] * self.n_layers\n",
    "        layers_net = [None] * self.n_layers\n",
    "        \n",
    "        \n",
    "        layer_input = X\n",
    "        #print('[foward_propagation] layer_input \\n',layer_input)\n",
    "        \n",
    "        layers_net[0] = np.array(layer_input.ravel())\n",
    "        for layer_index in range(self.n_layers - 1):\n",
    "            n_examples = layer_input.shape[0]\n",
    "            print('n_examples',n_examples,'layer_input',layer_input.shape)\n",
    "            layer_input = np.c_[ layer_input, np.ones(784) ]  \n",
    "            print('layer_input after add bias \\n',type(layer_input),layer_input.shape)\n",
    "            \n",
    "            #layer_input = layer_input.reshape(-1,1)\n",
    "            #layer_weights = self.weights[layer_index].reshape(-1,1)\n",
    "            #print('layer_weights shape',layer_weights.transpose().shape,'layer_input shape' , layer_input.shape)\n",
    "            layers_input[layer_index] = layer_input\n",
    "            layer_weights = self.weights[layer_index]\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_input \\n', layer_input,'shape', layer_input.shape)\n",
    "            #print('[foward_propagation] layer_index',layer_index, ' layer_weights \\n', layer_weights)\n",
    "            print(layer_input.shape)                       \n",
    "            layers_net[layer_index + 1] = self.net(layer_input,layer_weights)\n",
    "            #print('[foward_propagation] next layer_index',layer_index + 1, ' layers_net ', layers_net[layer_index + 1])\n",
    "                   \n",
    "            layer_output = self.sigmoid(layers_net[layer_index + 1])\n",
    "            \n",
    "            #print('[foward_propagation] next layer_index',layer_index + 1, ' layer_output ',layer_output)\n",
    "            \n",
    "            layer_input = layer_output\n",
    "\n",
    "        layers_input[self.n_layers - 1] = np.append(layer_output, 1) \n",
    "        #print('[foward_propagation] layers_input \\n',layers_input)\n",
    "        return layers_input, layers_net\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        layers_input, layers_net = self.foward_propagation(X)\n",
    "        Y_hat = layers_input[-1][:-1]\n",
    "        return Y_hat\n",
    "    \n",
    "    def net(self,X,W):\n",
    "        print('net', X.shape,W.shape)\n",
    "        return np.dot(X,W.transpose())\n",
    "    \n",
    "    def sigmoid(self,value):\n",
    "        sig = 1 / (1 + np.exp(-value))\n",
    "        return sig     \n",
    " \n",
    "    def error_part(self, value):\n",
    "        error_part = value * (1 - value) \n",
    "        return error_part\n",
    "    \n",
    "    def sigma(self, E,W):\n",
    "        return np.dot(E,W)\n",
    "   \n",
    " \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame([1,0])\n",
    "# print(X.values.shape)\n",
    "# y = pd.DataFrame([1])\n",
    "# print(y.values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 784, 10]\n",
      "n_examples 35 layer_input (35, 784)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-567-5332749d558d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# mlp.train(X.values, y.values,n_iter=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# mlp.predict(X.values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-565-93c9efe68cf3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, n_iter)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#print('train it',it)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-565-93c9efe68cf3>\u001b[0m in \u001b[0;36mback_propagation\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m#print('x shape',n_samples)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mlayers_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfoward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;31m#print('[back_propagation] layers_net \\n',layers_net,end='\\n\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m#print('[back_propagation] layers_input \\n',layers_input,end='\\n\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-565-93c9efe68cf3>\u001b[0m in \u001b[0;36mfoward_propagation\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mn_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'n_examples'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'layer_input'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mlayer_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mlayer_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layer_input after add bias \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "mlp = MLPerceptron(layers_len = [784, 784, 10],eta=0.5,random_state=50) #[784, 784, 10] #\n",
    "\n",
    "# mlp.train(X.values, y.values,n_iter=100)   \n",
    "# mlp.predict(X.values)\n",
    "mlp.train(X_train, y_train,n_iter=100)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
