{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from tensorflow.python.ops import math_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features,labels,batch_size):\n",
    "    display('train_input_fn features ',type(features))\n",
    "    display('train_input_fn labels',type(labels))\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
    "    \n",
    "    return dataset.shuffle(1000,seed=42).repeat().batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features,labels,batch_size):\n",
    "    features = dict(features)\n",
    "    if labels is None:\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features,labels)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4128, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create input function\n",
    "housing = fetch_california_housing()\n",
    "#display(housing.feature_names)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "n,m = housing.data.shape\n",
    "scaled_housing_data_bias = np.c_[np.ones((n,1)),scaled_housing_data]\n",
    "\n",
    "\n",
    "df_housing = pd.DataFrame(scaled_housing_data_bias,columns=housing.feature_names + ['bias'])\n",
    "#display(df_housing)\n",
    "X = df_housing\n",
    "y = housing.target.reshape(-1,1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "display(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(features,labels,mode,params):\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "    \n",
    "        \"\"\"DNN with 2 hidden layers , and dropout of 0.1 probability\"\"\"\n",
    "        input_layer = tf.feature_column.input_layer(features,\n",
    "                                                   params['feature_columns'])\n",
    "\n",
    "        hidden1 = tf.layers.dense(input_layer,units=params['n_hidden1'],\n",
    "                                 activation=tf.nn.relu)\n",
    "        dropout1 = tf.layers.dropout(inputs=hidden1,rate=0.1, \n",
    "                                     training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        hidden2 = tf.layers.dense(dropout1,units=params['n_hidden2'],\n",
    "                                 activation=tf.nn.relu)\n",
    "        dropout2 = tf.layers.dropout(inputs=hidden2,rate=0.1, \n",
    "                                     training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        \n",
    "        #compute output\n",
    "        output = tf.layers.dense(dropout2,params['n_output'])\n",
    "        \n",
    "        #compute predictions\n",
    "        predicted_value = tf.cast(output,tf.float64)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions = {\n",
    "                'predicted_value' : predicted_value\n",
    "            }\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode,predictions=predictions)\n",
    "    \n",
    "              \n",
    "        \n",
    "        #compute loss\n",
    "        loss = tf.losses.mean_squared_error(labels=labels,\n",
    "                                             predictions=predicted_value)\n",
    "        \n",
    "\n",
    "\n",
    "        rmse = tf.metrics.root_mean_squared_error(labels,predicted_value)\n",
    "        metrics = {'rmse':rmse}\n",
    "        #tf.summary.scalar('mse',accuracy[1])\n",
    "       \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode,loss = loss,\n",
    "                                             eval_metric_ops=metrics)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(loss,\n",
    "                                     global_step = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='MedInc', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='HouseAge', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='AveRooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='AveBedrms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Population', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='AveOccup', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Latitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='bias', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'my_model_2', '_tf_random_seed': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FC710B4FC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.RunConfig(tf_random_seed=0)\n",
    "\n",
    "feature_columns = []\n",
    "print(type(X))\n",
    "for key in df_housing.columns.values:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    \n",
    "display(feature_columns)\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns':feature_columns,\n",
    "        'n_hidden1': 10,\n",
    "        'n_hidden2': 10,\n",
    "        'n_output': 1\n",
    "    },\n",
    "    model_dir = 'my_model_2',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_input_fn features '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'train_input_fn labels'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into my_model_2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 8.699994, step = 0\n",
      "INFO:tensorflow:global_step/sec: 390.137\n",
      "INFO:tensorflow:loss = 0.6030164, step = 100 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.723\n",
      "INFO:tensorflow:loss = 0.40606594, step = 200 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.12\n",
      "INFO:tensorflow:loss = 0.71435744, step = 300 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 795.608\n",
      "INFO:tensorflow:loss = 0.44873896, step = 400 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.04\n",
      "INFO:tensorflow:loss = 0.45823926, step = 500 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.571\n",
      "INFO:tensorflow:loss = 0.39416528, step = 600 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.269\n",
      "INFO:tensorflow:loss = 0.59160376, step = 700 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.576\n",
      "INFO:tensorflow:loss = 0.59943277, step = 800 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 771.29\n",
      "INFO:tensorflow:loss = 0.33880776, step = 900 (0.130 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into my_model_2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5781055.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1fc7136e848>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_step = 1000\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(X_train,y_train,batch_size),\n",
    "    steps=train_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-09T15:22:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from my_model_2\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-09-15:22:53\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.4159876, rmse = 0.64614105\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: my_model_2\\model.ckpt-1000\n",
      "eval_result {'loss': 0.4159876, 'rmse': 0.64614105, 'global_step': 1000}\n",
      "eval_result 0.64614105\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(X_test,y_test,batch_size))\n",
    "\n",
    "print('eval_result',eval_result)\n",
    "print('eval_result',eval_result['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
